{
  "What are the theoretical foundations of compositionality in NLP?": {
    "https://openalex.org/W2016954686": "However, compositionality in natural language is much more complex than the rigid, arithmetic-like version such data adheres to, and artificial compositionality tests thus do not allow us to determine how neural models deal with more realistic forms of compositionality. In this work, we re-instantiate three compositionality tests from the literature and reformulate them for neural machine translation (NMT).Our results highlight that: i) unfavourably, models trained on more data are more compositional; ii) models are sometimes less compositional than expected, but sometimes more, exemplifying that different levels of compositionality are required, and models are not always able to modulate between them correctly; iii) some of the non-compositional behaviours are mistakes, whereas others reflect the natural variation in data. Apart from an empirical study, our work is a call to action: we should rethink the evaluation of compositionality in neural networks and develop benchmarks using real data to evaluate compositionality on natural language, where composing meaning is not as straightforward as doing the math. It argues that two seemingly unrelated questions are actually intimately related: whether thematic arguments should be severed from the verb and whether there is a syntactic difference between specifiers and complements. The book closes with a discussion of compositionality in some detail, arguing that a semantics based on conjunction is compositional. We review problems with theories that focus on reference and truth and argue for a theory based on the expression of structured cognitive propositions, identified with thoughts. The fact that thoughts have parts is key to compositionality as well as word meaning. Chief among them are the forces of both linguistic and extra-linguistic context dependence, the former typically relating to issues of compositionality and various kinds of embedding behavior.",
    "https://openalex.org/W131931019": "Formal semantics in the Fregean tradition has developed methods to account for the infinity of sentential meaning based on the crucial insight of compositionality, the idea that meaning of sentences is built incrementally by combining the meanings of their constituents. We adopt, in particular, the idea that word meaning can be approximated by the patterns of co-occurrence of words in corpora from statistical semantics, and the idea that compositionality can be captured in terms of a syntax-driven calculus of function application from formal semantics.",
    "https://openalex.org/W2045335691": "As a response to this controversy, we present a set of tests that provide a bridge between, on the one hand, the vast amount of linguistic and philosophical theory about compositionality of language and, on the other, the successful neural models of language. We collect different interpretations of compositionality and translate them into five theoretically grounded tests for models that are formulated on a task-independent level. This is the second part of a two-part article on compositionality, i.e. In the first, Pagin and Westerst\u00e5hl (2010), we provide a general historical background, a formal framework, definitions, and a survey of variants of compositionality. The book closes with a discussion of compositionality in some detail, arguing that a semantics based on conjunction is compositional.",
    "https://openalex.org/W148937678": "This is the first part of a two-part article on semantic compositionality, that is, the principle that the meaning of a complex expression is determined by the meanings of its parts and the way they are put together. Here we provide a brief historical background, a formal framework for syntax and semantics, precise definitions, and a survey of variants of compositionality. This is the second part of a two-part article on compositionality, i.e. the principle that the meaning of a complex expression is determined by the meanings of its parts and the way they are put together. In the first, Pagin and Westerst\u00e5hl (2010), we provide a general historical background, a formal framework, definitions, and a survey of variants of compositionality.",
    "https://openalex.org/W140802360": "This new fluid or liquid perspective in cognitive science and cognitive neuroscience can be regarded as a contribution towards bridging the gap between the discrete, abstract symbolic description of propositions in the mind, and their continuous, numerical implementation in self-organizing neural networks modelling the neural information processing in the human brain."
  },
  "What strategies exist for low-resource langauages?": {
    "https://openalex.org/W4285123703": "Abstract It is well known that AI-based language technology\u2014large language models, machine translation systems, multilingual dictionaries, and corpora\u2014is currently limited to three percent of the world\u2019s most widely spoken, financially and politically backed languages. In response, recent efforts have sought to address the \u201cdigital language divide\u201d by extending the reach of large language models to \u201cunderserved languages.\u201d We show how some of these efforts tend to produce flawed solutions that adhere to a hard-wired representational preference for certain languages, which we call language modeling bias. Language modeling bias is a specific and under-studied form of linguistic bias were language technology by design favors certain languages, dialects, or sociolects with respect to others. We show that language modeling bias can result in systems that, while being precise regarding languages and cultures of dominant powers, are limited in the expression of socio-culturally relevant notions of other communities. We further argue that at the root of this problem lies a systematic tendency of technology developer communities to apply a simplistic understanding of diversity which does not do justice to the more profound differences that languages, and ultimately the communities that speak them, embody. We introduce a suite of resources for evaluating and achieving English dialect invariance. The resource is called Multi-VALUE, a controllable rule-based translation system spanning 50 English dialects and 189 unique linguistic features. Abstract Italy is characterized by a one-of-a-kind linguistic diversity landscape in Europe, which implicitly encodes local knowledge, cultural traditions, artistic expressions, and history of its speakers. However, most local languages and dialects in Italy are at risk of disappearing within a few generations. The NLP community has recently begun to engage with endangered languages, including those of Italy. Yet, most efforts assume that these varieties are under-resourced language monoliths with an established written form and homogeneous functions and needs, and thus highly interchangeable with each other and with high-resource, standardized languages. We advocate for a shift in the paradigm from machine-centric to speaker-centric NLP, and provide recommendations and opportunities for work that prioritizes languages and their speakers over technological advances. To facilitate the process, we finally propose building a local community towards responsible, participatory efforts aimed at supporting vitality of languages and dialects of Italy. This thesis addresses the significant underrepresentation of certain languages in Natural Language Processing (NLP), focusing on low-resource languages with complex morphology. Chapters 1 and 2 introduce the thesis, outlining goals and foundational concepts, including neural network architectures and the potential of NMT in low-resource settings. Chapter 6 extends the study to Dravidian languages, emphasizing SentencePiece's superiority and optimal subword dictionary size.Chapter 7 broadens the scope to diverse languages with distinct morphologies, introducing a novel pre-training objective, PT-Inflect. PT-Inflect outperforms models trained solely on parallel data, though computationally expensive back-translation remains superior for some languages. The combination of PT-Inflect and back-translation emerges as the optimal choice for Lithuanian.The thesis concludes by highlighting the broader implications: advancing NLP research and applications for underrepresented languages facilitates global participation, enabling diverse communities to engage in the predominantly English-driven global conversation. Large Language Models, the dominant starting point for Natural Language Processing (NLP) applications, fail at a higher rate for speakers of English dialects other than Standard American English (SAE). This work presents the development of the translation component in a multistage, multilevel, multimode, multilingual and dynamic deliberative (M4D2) system, built to facilitate automated moderation and translation in the languages of five European countries: Italy, Ireland, Germany, France and Poland. In this work, we describe the development of neural machine translation (NMT) models for these domains for six European languages: Italian, English (included as the second official language of Ireland), Irish, German, French and Polish. We compare our results produced by the domain-adapted systems with those produced by Google Translate, and demonstrate that fast, high-quality systems can be produced that facilitate multilingual deliberation in a secure environment. Existing large language models (LLMs) that mainly focus on Standard American English (SAE) often lead to significantly worse performance when being applied to other English dialects. While existing mitigations tackle discrepancies for individual target dialects, they assume access to high-accuracy dialect identification systems.",
    "https://openalex.org/W2807710978": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Abteen Ebrahimi, Manuel Mager, Arturo Oncevay, Vishrav Chaudhary, Luis Chiruzzo, Angela Fan, John Ortega, Ricardo Ramos, Annette Rios, Ivan Vladimir Meza Ruiz, Gustavo Gim\u00e9nez-Lugo, Elisabeth Mager, Graham Neubig, Alexis Palmer, Rolando Coto-Solano, Thang Vu, Katharina Kann. Manuel Mager, Arturo Oncevay, Abteen Ebrahimi, John Ortega, Annette Rios, Angela Fan, Ximena Gutierrez-Vasques, Luis Chiruzzo, Gustavo Gim\u00e9nez-Lugo, Ricardo Ramos, Ivan Vladimir Meza Ruiz, Rolando Coto-Solano, Alexis Palmer, Elisabeth Mager-Hois, Vishrav Chaudhary, Graham Neubig, Ngoc Thang Vu, Katharina Kann. Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas. How can language technology address the diverse situations of the world\u2019s languages? In one view, languages exist on a resource continuum and the challenge is to scale existing solutions, bringing under-resourced languages into the high-resource world. In another view, presented here, the world\u2019s language ecology includes standardised languages, local languages, and contact languages. These are often subsumed under the label of \u201cunder-resourced languages\u201d even though they have distinct functions and prospects. I explore this position and propose some ecologically-aware language technology agendas. In modern linguistic discourse, the intersection of technology and language diversity is a central theme of academic discourse. The rapidly changing technological landscape presents both opportunities and challenges to linguistic plurality. Advancements in digital technologies such as generative artificial intelligence and large language modeling are changing the linguistic dynamics both in favour (of) and against the endangered languages. The overwhelmingly predominant use of English in the digital space relegates smaller languages and threatens them to push out of popular use. Digital archiving plays a crucial role in language documentation and revival efforts for endangered languages. This paper presents a neural machine translation model and dataset for the Chibchan language Bribri, with an average performance of BLEU 16.9\u00b11.7. We discuss the challenges entailed in managing training input from languages without standard orthographies, we provide evidence of successful learning of Bribri grammar, and also examine the translations of structures that are infrequent in major Indo-European languages, such as positional verbs, ergative markers, numerical classifiers and complex demonstrative systems. Transformer language models have become fundamental components of NLP based pipelines. Although several Transformer have been introduced to serve many languages, there is a shortage of models pre-trained for low-resource and Indigenous languages in particular. In this work, we introduce IndT5, the first Transformer language model for Indigenous languages. To train IndT5, we build IndCorpus, a new corpus for 10 Indigenous languages and Spanish. We also present the application of IndT5 to machine translation by investigating different approaches to translate between Spanish and the Indigenous languages as part of our contribution to the AmericasNLP 2021 Shared Task on Open Machine Translation. Machine translation for low-resource languages, such as Guarani, is a challenging task due to the lack of data.",
    "https://openalex.org/W4287758476": "We explore whether GPT, the large-language model underlying the artificial intelligence chatbot ChatGPT, can be used as a tool for automated psychological text analysis in several languages. Across 15 datasets (n = 47,925 manually annotated tweets and news headlines), we tested whether different versions of GPT (3.5 Turbo, 4, and 4 Turbo) can accurately detect psychological constructs (sentiment, discrete emotions, offensiveness, and moral foundations) across 12 languages. Moreover, GPT\u2019s performance has improved across successive versions of the model, particularly for lesser-spoken languages. Overall, GPT may be superior to many existing methods of automated text analysis, since it achieves relatively high accuracy across many languages, requires no training data, and is easy to use with simple prompts (e.g., \u201cis this text negative?\u201d) and little coding experience. We argue that GPT and other large-language models may democratize automated text analysis by making advanced natural language processing capabilities more accessible, and may help facilitate more cross-linguistic research with understudied languages. Recent developments in deep learning architectures represent a shift away from Recurrent and Convolutional neural networks and the increasing adoption of Transformer language models. This survey paper provides a discussion of the open challenges in NLP and sentiment analysis. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. Highlighting the potential for cross-fertilizing AI with libraries, the conclusion suggests that while AI may transform the workings of the library, libraries can also play a key role in the future development of AI. Numerous models and techniques to detect Smishing attacks have been introduced for high-resource languages, yet few target low-resource languages such as Swahili. We then exemplify the importance of each question in our augmented datasheet based on in-depth literature reviews of speech data used in domains such as machine learning, linguistics, and health. We additionally examine how failures impact users' willingness to rely on voice assistants for future tasks.",
    "https://openalex.org/W3136221257": "We present the findings of SemEval-2023 Task 2 on Fine-grained Multilingual Named Entity Recognition (MultiCoNER 2). Divided into 13 tracks, the task focused on methods to identify complex fine-grained named entities (like WRITTENWORK, VEHICLE, MUSICALGRP) across 12 languages, in both monolingual and multilingual scenarios, as well as noisy settings. Abstract To obtain extensive annotated data for under-resourced languages is challenging, so in this research, we have investigated whether it is beneficial to train models using multi-task learning. This paper works on code-mixed YouTube comments for Tamil, Malayalam, and Kannada languages. Analysis of fine-tuned models indicates the preference of multi-task learning over single-task learning resulting in a higher weighted F1-score on all three languages. We apply two multi-task learning approaches to three Dravidian languages: Kannada, Malayalam, and Tamil. In this paper, we study pre-trained sequence-to-sequence models for a group of related languages, with a focus on Indic languages. We present IndicBART, a multilingual, sequence-to-sequence pre-trained model focusing on 11 Indic languages and English. IndicBART utilizes the orthographic similarity between Indic scripts to improve transfer learning between similar Indic languages. Our experiments on NMT and extreme summarization show that a model specific to related languages like IndicBART is competitive with large pre-trained models like mBART50 despite being significantly smaller. It also performs well on very low-resource translation scenarios where languages are not included in pre-training or fine-tuning. Script sharing, multilingual training, and better utilization of limited model capacity contribute to the good performance of the compact IndicBART model.",
    "https://openalex.org/W4388953014": "The attention mechanism performs well for the Neural Machine Translation (NMT) task, but heavily depends on the context vectors generated by the attention network to predict target words. By encoding the source sentence with the current decoded feature through the CARU, CAAtt is capable of achieving translation content-adaptive representations, which attention weights are contributed and enhanced by our proposed L1expNx normalization. Experiments on the WMT14, WMT17, and Multi30k translation tasks show that the proposed model achieves improvements in BLEU scores and enhancement of convergence over the attention-based plain NMT model. This paper discusses the main challenges and solution strategies of low-resource machine translation, and proposes a novel translation method combining migration learning and multi-view training. In a low-resource environment, neural machine translation models are prone to problems such as insufficient generalization performance, inaccurate translation of long sentences, difficulty in processing unregistered words, and inaccurate translation of domain-specific terms due to their heavy reliance on massively parallel corpora. Migration learning gradually adapts to the translation tasks of low-resource languages in the process of fine-tuning by borrowing the general translation knowledge of high-resource languages and utilizing pre-training models such as BERT, XLM-R, and so on. Multi-perspective training, on the other hand, emphasizes the integration of source and target language features from multiple levels, such as word level, syntax and semantics, in order to enhance the model's comprehension and translation ability under limited data conditions. In the experiments, the study designed an experimental scheme containing pre-training model selection, multi-perspective feature construction, and migration learning and multi-perspective fusion, and compared the performance with randomly initialized Transformer model, pre-training-only model, and traditional statistical machine translation model.",
    "https://openalex.org/W3198189804": "Machine translation systems, including emerging large language models, have the potential to expand access to translation services, but their merits and limitations in clinical practice remain poorly defined. We aimed to assess the performance of Google Translate and ChatGPT for multilingual translation of pediatric discharge instructions. METHODS Twenty standardized discharge instructions for pediatric conditions were translated into Spanish, Brazilian Portuguese, and Haitian Creole by professional translation services, Google Translate and ChatGPT-4.0, and evaluated for adequacy (preserved information), fluency (grammatical correctness), meaning (preserved connotation), and severity (clinical harm), along with assessment of overall preference. Domain-level ratings and preferred translation source were summarized with descriptive statistics and compared with professional translations. RESULTS Google Translate and ChatGPT demonstrated similar domain-level ratings to professional translations for Spanish and Portuguese. For Haitian Creole, compared with both Google Translate and ChatGPT, professional translations demonstrated significantly greater adequacy, fluency meaning, and severity scores. ChatGPT (33.3%, P &amp;lt; .001) and Google Translate (23.3%, P = .024) contained more potentially clinically significant errors (severity score \u22643) for Haitian Creole than professional translations (8.3%). Professional Haitian Creole (48.3%) and Portuguese (43.3%), but not Spanish (15%), translations were most frequently preferred among translation sources. CONCLUSIONS Machine translation platforms have comparable performance to professional translations for Spanish and Portuguese but shortcomings in quality, accuracy, and preference persist for Haitian Creole. Diverse multilingual training data are needed, along with regulations ensuring safe and equitable applications of machine translation in clinical practice. The Machine Translation System (MTS) serves as effective tool for communication by translating text or speech from one language to another language. Recently, neural machine translation (NMT) has become popular for its performance and cost-effectiveness. However, NMT systems are restricted in translating low-resource languages as a huge quantity of data is required to learn useful mappings across languages. The need for an efficient translation system becomes obvious in a large multilingual environment like India. Indian languages (ILs) are still treated as low-resource languages due to unavailability of corpora. In order to address such an asymmetric nature, the multilingual neural machine translation (MNMT) system evolves as an ideal approach in this direction. It is also helpful for improving low-resource translation. In this article, we propose an MNMT system to address the issues related to low-resource language translation. Our model comprises two MNMT systems, i.e., for English-Indic (one-to-many) and for Indic-English (many-to-one) with a shared encoder-decoder containing 15 language pairs (30 translation directions). Since most of IL pairs have a scanty amount of parallel corpora, not sufficient for training any machine translation model, we explore various augmentation strategies to improve overall translation quality through the proposed model. In addition, the article addresses the use of language relationships (in terms of dialect, script, etc.), particularly about the role of high-resource languages of the same family in boosting the performance of low-resource languages. Moreover, the experimental results also show the advantage of back-translation and domain adaptation for ILs to enhance the translation quality of both source and target languages."
  },
  "Evaluation without humans.": {
    "https://openalex.org/W2101105183": "Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation.However, there has been little work exploring useful architectures for attention-based NMT.This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time.We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions.With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout.Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT'15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art. Applying this approach to image captioning, our results on the MSCOCO test server establish a new state-of-the-art for the task, achieving CIDEr / SPICE / BLEU-4 scores of 117.9, 21.5 and 36.9, respectively.",
    "https://openalex.org/W2159107349": "We investigate evaluation metrics for dialogue response generation systems where supervised labels, such as task completion, are not available.Recent works in response generation have adopted metrics from machine translation to compare a model's generated response to a single target response.We show that these metrics correlate very weakly with human judgements in the non-technical Twitter domain, and not at all in the technical Ubuntu domain.We provide quantitative and qualitative results highlighting specific weaknesses in existing metrics, and provide recommendations for future development of better automatic evaluation metrics for dialogue systems. We investigate evaluation metrics for dialogue response generation systems where supervised labels, such as task completion, are not available. Recent works in response generation have adopted metrics from machine translation to compare a model's generated response to a single target response. We show that these metrics correlate very weakly with human judgements in the non-technical Twitter domain, and not at all in the technical Ubuntu domain. We provide quantitative and qualitative results highlighting specific weaknesses in existing metrics, and provide recommendations for future development of better automatic evaluation metrics for dialogue systems. Proceedings of the Third Conference on Machine Translation: Shared Task Papers. Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers. Proceedings of the Ninth Workshop on Statistical Machine Translation. Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1). Proceedings of the Second Conference on Machine Translation. This paper describes Meteor 1.3, our submission to the 2011 EMNLP Workshop on Statistical Machine Translation automatic evaluation metric tasks. We include Ranking and Adequacy versions of the metric shown to have high correlation with human judgments of translation quality as well as a more balanced Tuning version shown to outperform BLEU in minimum error rate training for a phrase-based Urdu-English system. This paper presents the results of the WMT12 shared tasks, which included a translation task, a task for machine translation evaluation metrics, and a task for run-time estimation of machine translation quality. We conducted a large-scale manual evaluation of 103 machine translation systems submitted by 34 teams. We used the ranking of these systems to measure how strongly automatic metrics correlate with human judgments of translation quality for 12 evaluation metrics.",
    "https://openalex.org/W4392669868": "To better understand the limitations of abstractive systems, as well as the suitability of existing evaluation metrics, we benchmark faithfulness metrics against fine-grained human annotations for model-generated summaries of a patient's Brief Hospital Course. Thus, Automatic Story Evaluation (ASE) and Generation (ASG) could benefit society in multiple ways, but they are challenging tasks which require high-level human abilities such as creativity, reasoning, and deep understanding. Meanwhile, Large Language Models (LLMs) now achieve state-of-the-art performance on many NLP tasks. We perform an extensive analysis of the correlations between LLM ratings, other automatic measures, and human annotations, and we explore the influence of prompting on the results and the explainability of LLM behaviour. Most notably, we find that LLMs outperform current automatic measures for system-level evaluation but still struggle at providing satisfactory explanations for their answers. Pierre Colombo, Victor Pellegrain, Malik Boudiaf, Myriam Tami, Victor Storchan, Ismail Ayed, Pablo Piantanida. Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. The evaluation of natural language processing (NLP) systems is crucial for advancing the field, but current benchmarking approaches often assume that all systems have scores available for all tasks, which is not always practical. We validate our methods and demonstrate their effectiveness in addressing the challenge of missing system evaluation on an entire task. Our new benchmark STAKEOUT allows for a robust evaluation framework: we conduct extensive numerical experiments which demonstrate that LAROUSSE outperforms previous methods, and which allows to identify interesting factor of detection rate variations. Proprietary and closed APIs are becoming increasingly common to process natural language, and are impacting the practical applications of natural language processing, including few-shot classification. Third, we propose an improved experimental setting and compile a benchmark of eight datasets involving multiclass classification in four different languages, with up to 151 classes. We evaluate our methods using eight backbone models, along with an episodic evaluation over 1,000 episodes, which demonstrate the superiority of transductive inference over the standard inductive setting. As dialogue systems become more popular, evaluation of their response quality gains importance. Although qualities like coherence and fluency are readily measured with well-worn automatic metrics, evaluating engagingness often relies on human assessment, which is a costly and time-consuming process. Existing automatic engagingness metrics evaluate the response without the conversation history, are designed for one dataset, or have limited correlation with human annotations. Given that dialogue systems are increasingly available in languages beyond English, multilingual evaluation capabilities are essential. We propose that large language models (LLMs) may be used for evaluation of engagingness in dialogue through prompting, and ask how prompt constructs and translated prompts compare in a multilingual setting. We provide a prompt-design taxonomy for engagingness and find that using selected prompt elements with LLMs, including our comprehensive definition of engagingness, outperforms state-of-the-art methods on evaluation of engagingness in dialogue across multiple languages."
  },
  "How does tokenization work?": {
    "https://openalex.org/W2037450062": "This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Tokenization is a fundamental preprocessing step for almost all NLP tasks. In this paper, we propose efficient algorithms for the WordPiece tokenization used in BERT, from single-word tokenization to general text (e.g., sentence) tokenization. We propose a novel algorithm whose tokenization complexity is strictly O(n). For general text, we further propose an algorithm that combines pre-tokenization (splitting the text into words) and our linear-time WordPiece method into a single pass. Experimental results show that our method is 8.2x faster than HuggingFace Tokenizers and 5.1x faster than TensorFlow Text on average for general text tokenization.",
    "https://openalex.org/W4206660322": "Until recently, most natural language processing (NLP) models operated over words, treating those as discrete and atomic tokens, but starting with byte-pair encoding (BPE), subword-based approaches have become dominant in many areas, enabling small vocabularies while still allowing for fast inference. We conclude that there is and likely will never be a silver bullet singular solution for all applications and that thinking seriously about tokenization remains important for many applications. These files are then passed through a pre-tokenization feature generator, and the resulting keywords are used to train the tokenizer from scratch."
  },
  "How does gender relate to language?": {
    "https://openalex.org/W2139875525": "This article reviews several computerized text analysis methods and describes how Linguistic Inquiry and Word Count (LIWC) was created and validated. LIWC is a transparent text analysis program that counts words in psychologically meaningful categories. Empirical results using LIWC demonstrate its ability to detect meaning in a wide variety of experimental settings, including to show attentional focus, emotionality, social relationships, thinking styles, and individual differences. LIWC has been used to efficiently classify texts along psychological dimensions and to predict behavioral outcomes, making it a text analysis tool widely used in the social sciences. LIWC can be considered to be a tool for applied natural language processing since, beyond classification, the relative uses of various LIWC categories can reflect the underlying psychology of demographic characteristics, honesty, health, status, relationship quality, group dynamics, or social context. Combining LIWC categories using new algorithms or using the processor to assess new categories and languages further extend the potential applications of LIWC. We analyzed 700 million words, phrases, and topic instances collected from the Facebook messages of 75,000 volunteers, who also took standard personality tests, and found striking variations in language with personality, gender, and age. In our open-vocabulary technique, the data itself drives a comprehensive exploration of language that distinguishes people, finding connections that are not captured with traditional closed-vocabulary word-category analyses. To date, this represents the largest study, by an order of magnitude, of language and personality. We propose that gendered wording (i.e., masculine- and feminine-themed words, such as those associated with gender stereotypes) may be a heretofore unacknowledged, institutional-level mechanism of inequality maintenance. Employing both archival and experimental analyses, the present research demonstrates that gendered wording commonly employed in job recruitment materials can maintain gender inequality in traditionally male-dominated occupations. Studies 1 and 2 demonstrated the existence of subtle but systematic wording differences within a randomly sampled set of job advertisements. Results confirmed that perceptions of belongingness (but not perceived skills) mediated the effect of gendered wording on job appeal (Study 5). The function of gendered wording in maintaining traditional gender divisions, implications for gender parity, and theoretical models of inequality are discussed. Do you use language corpora in your research or study, but find that you struggle with statistics? The book gives step-by-step guidance through the process of statistical analysis and provides multiple examples of how statistical techniques can be used to analyse and visualise linguistic data. This study introduces the linguistic style matching (LSM) algorithm for calculating verbal mimicry based on an automated textual analysis of function words. The LSM algorithm was applied to language generated during a small group discussion in which 70 groups comprised of 324 individuals engaged in an information search task either face-to-face or via text-based computer-mediated communication. Other language features were also related to the groups\u2019 cohesiveness and performance, including word count, pronoun patterns, and verb tense. In total, the study demonstrates the effectiveness of using language to predict change in social psychological factors of interest. Abstract Precision Medicine implies a deep understanding of inter-individual differences in health and disease that are due to genetic and environmental factors. Furthermore, the design of the majority of algorithms ignore the sex and gender dimension and its contribution to health and disease differences among individuals. Failure in accounting for these differences will generate sub-optimal results and produce mistakes as well as discriminatory outcomes. In this review we examine the current sex and gender gaps in a subset of biomedical technologies used in relation to Precision Medicine.",
    "https://openalex.org/W1995519658": "In this paper, we develop a framework to demonstrate how the temporal dynamics of the embedding can be leveraged to quantify changes in stereotypes and attitudes toward women and ethnic minorities in the 20th and 21st centuries in the United States. The embedding captures global social shifts -- e.g., the women's movement in the 1960s and Asian immigration into the U.S -- and also illuminates how specific adjectives and occupations became more closely associated with certain populations over time. We first learn a latent representation of the input sentence which is grounded in a language translation model in order to better preserve the meaning of the sentence while reducing stylistic properties. Gender stereotypes are manifest in most of the world's languages and are consequently propagated or amplified by NLP systems. Although research has focused on mitigating gender stereotypes in English, the approaches that are commonly employed produce ungrammatical sentences in morphologically rich languages. We present a novel approach for converting between masculine-inflected and feminine-inflected sentences in such languages. By evaluating our approach using four different languages, we show that, on average, it reduces gender stereotyping by a factor of 2.5 without any sacrifice to grammaticality. However, using these data to understand phenomena in a broader population is difficult due to their non-representativeness and the bias of statistical inference tools towards dominant languages and groups. To learn demographic attributes, we create a new multimodal deep neural architecture for joint classification of age, gender, and organization-status of social media users that operates in 32 languages. Speakers of different languages must attend to and encode strikingly different aspects of the world in order to use their language correctly (Sapir, 1921; Slobin, 1996). One such difference is related to the way gender is expressed in a language. However, many other languages do have grammatical gender systems and so such knowledge would be encoded. Apart from morphological agreement, demographic factors (gender, age, etc.) also influence our use of language in terms of word choices or even on the level of syntactic constructions (Tannen, 1991; Pennebaker et al., 2003). Our contribution is two-fold: (1) the compilation of large datasets with speaker information for 20 language pairs, and (2) a simple set of experiments that incorporate gender information into NMT for multiple language pairs. Our experiments show that adding a gender feature to an NMT system significantly improves the translation quality for some language pairs. It has long been claimed that Homo sapiens is the only species that has language, but only recently has it been recognized that humans also have an unusual pattern of growth and development. We propose that several different forms of selection applied in infancy and childhood; and that, in adolescence, elaborated vocal behaviors played a role in courtship and intrasexual competition, enhancing fitness and ultimately integrating performative and pragmatic skills with linguistic knowledge in a broad faculty of language. A theoretical consequence of our proposal is that fossil evidence of the uniquely human stages may be used, with other findings, to date the emergence of language. If important aspects of language cannot appear until sexual maturity, as we propose, then a second consequence is that the development of language requires the whole of modern human ontogeny. Our life history model thus offers new ways of investigating, and thinking about, the evolution, development, and ultimately the nature of human language. Gender differences in dominance varied as a function of several contextual variables: individuation, the accessibility of gender stereotypes, and the fit between group task and stereotype.",
    "https://openalex.org/W3035070478": "Abstract Machine translation (MT) technology has facilitated our daily tasks by providing accessible shortcuts for gathering, processing, and communicating information. As a relatively new field of inquiry, studies of gender bias in MT still lack cohesion. To this end, we: i) critically review current conceptualizations of bias in light of theoretical insights from related disciplines, ii) summarize previous analyses aimed at assessing gender bias in MT, iii) discuss the mitigating strategies proposed so far, and iv) point toward potential directions for future work. Creating the Babel Fish, a tool that helps individuals translate speech between any two languages, requires advanced technological innovation and linguistic expertise. Although conventional speech-to-speech translation systems composed of multiple subsystems performing translation in a cascaded fashion exist1\u20133, scalable and high-performing unified systems4,5 remain underexplored. To address this gap, here we introduce SEAMLESSM4T\u2013Massively Multilingual and Multimodal Machine Translation\u2013a single model that supports speech-to-speech translation (101 to 36 languages), speech-to-text translation (from 101 to 96 languages), text-to-speech translation (from 96 to 36 languages), text-to-text translation (96 languages) and automatic speech recognition (96 languages). Built using a new multimodal corpus of automatically aligned speech translations and other publicly available data, SEAMLESSM4T is one of the first multilingual systems that can translate from and into English for both speech and text. Moreover, it outperforms the existing state-of-the-art cascaded systems, achieving up to 8% and 23% higher BLEU (Bilingual Evaluation Understudy) scores in speech-to-text and speech-to-speech tasks, respectively. Beyond quality, when tested for robustness, our system is, on average, approximately 50% more resilient against background noise and speaker variations in speech-to-text tasks than the previous state-of-the-art systems. We evaluated SEAMLESSM4T on added toxicity and gender bias to assess translation safety. Finally, all contributions in this work are publicly available for non-commercial use to propel further research on inclusive speech translation technologies. SEAMLESSM4T is a single machine translation tool that supports speech-to-speech translation, speech-to-text translation, text-to-speech translation, text-to-text translation and automatic speech recognition between up to 100 languages. Recently, speech-to-text translation has attracted more and more attention and many studies have emerged rapidly. In this paper, we present a comprehensive survey on direct speech translation aiming to summarize the current state-of-the-art techniques. We analyze and summarize the application issues, which include real-time, segmentation, named entity, gender bias, and code-switching. Machine Translation (MT) continues to make significant strides in quality and is increasingly adopted on a larger scale. Along this line, this paper offers a meticulous assessment of three commercial MT systems - Google Translate, DeepL, and Modern MT - with a specific focus on gender translation and bias. For three language pairs (English-Spanish, English-Italian, and English-French), we scrutinize the behavior of such systems at several levels of granularity and on a variety of naturally occurring gender phenomena in translation. Our study takes stock of the current state of online MT tools, by revealing significant discrepancies in the gender translation of the three systems, with each system displaying varying degrees of bias despite their overall translation quality. The machine translation (MT) task is typically formulated as that of returning a single translation for an input segment. However, in many cases, multiple different translations are valid and the appropriate translation may depend on the intended target audience, characteristics of the speaker, or even the relationship between speakers. We introduce an annotated dataset (CoCoA-MT) and an associated evaluation metric for training and evaluating formality-controlled MT models for six diverse target languages. Gender bias is largely recognized as a problematic phenomenon affecting language technologies, with recent studies underscoring that it might surface differently across languages. Such protocols overlook key features of grammatical gender languages, which are characterized by morphosyntactic chains of gender agreement, marked on a variety of lexical items and parts-of-speech (POS). To overcome this limitation, we enrich the natural, gender-sensitive MuST-SHE corpus (Bentivogli et al., 2020) with two new linguistic annotation layers (POS and agreement chains), and explore to what extent different lexical categories and agreement phenomena are impacted by gender skews. Focusing on speech translation, we conduct a multifaceted evaluation on three language directions (English-French/Italian/Spanish), with models trained on varying amounts of data and different word segmentation techniques. By shedding light on model behaviours, gender bias, and its detection at several levels of granularity, our findings emphasize the value of dedicated analyses beyond aggregated overall results. Direct speech translation (ST) has shown to be a complex task requiring knowledge transfer from its sub-tasks: automatic speech recognition (ASR) and machine translation (MT). Moreover, we analyze eventual drawbacks of this approach and how to alleviate them maintaining the benefits in terms of translation quality.",
    "https://openalex.org/W2127063197": "The Woman Who Climbed Up the House 2. Authoring Oneself as a Woman in Nepal V. In a work with far-reaching implications, Chela Sandoval does no less than revise the genealogy of theory over the past thirty years, inserting what she terms Third World feminism into the narrative in a way that thoroughly alters our perspective on contemporary culture and subjectivity.What Sandoval has identified is a language, a rhetoric of resistance to postmodern cultural conditions. Out of these emerged a new activity of consciousness and language Sandoval calls the of the oppressed. Language is closely linked to our social relationships and is the medium through which we participate in a variety of social activities. This fascinating study explores the important role of language in various aspects of our social life, such as identity, gender relations, class, kinship, status, and hierarchies. Drawing on data from over thirty different languages and societies, it shows how language is more than simply a form of social action; it is also an effective tool with which we formulate models of social life and conduct. Providing a unified way of accounting for a variety of social phenomena, this book will be welcomed by all those interested in the interaction between language, culture, and society. Introduction Knowledge of Language Variation Language and Society Sociolinguistics and the Sociology of Language Methodological Concerns Overview Further Reading Part I: Languages and Communities: 2. Languages, Dialects, and Varieties Language or Dialect? Language Variation Regional Variation The Linguistic Variable Social Variation Data Collection and Analysis Further Reading 7. Style refers to ways of speaking - how speakers use the resource of language variation to make meaning in social encounters. The emphasis is on how social meanings are made locally, in specific relationships, genres, groups and cultures, and on studying language variation as part of the analysis of spoken discourse.",
    "https://openalex.org/W2972972637": "More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. An increasing number of decisions regarding the daily lives of human beings are being controlled by artificial intelligence and machine learning (ML) algorithms in spheres ranging from healthcare, transportation, and education to college admissions, recruitment, provision of loans, and many more realms. Abstract The quality of human translation was long thought to be unattainable for computer translation systems. In a context-aware blind evaluation by human judges, CUBBITT significantly outperformed professional-agency English-to-Czech news translation in preserving text meaning (translation adequacy). While human translation is still rated as more fluent, CUBBITT is shown to be substantially more fluent than previous state-of-the-art systems. Moreover, most participants of a Translation Turing test struggle to distinguish CUBBITT translations from human translations. This work approaches the quality of human translation and even surpasses it in adequacy in certain circumstances.This suggests that deep learning may have the potential to replace humans in applications where conservation of meaning is the primary aim. We have recently seen work in machine learning, natural language processing, and deep learning that addresses such challenges in different subdomains. We then created a taxonomy for fairness definitions that machine learning researchers have defined in order to avoid the existing bias in AI systems. This paper investigates LLMs' behavior with respect to gender stereotypes, a known issue for prior models. We use a simple paradigm to test the presence of gender bias, building on but differing from WinoBias, a commonly used gender bias dataset, which is likely to be included in the training data of current LLMs. Our contributions in this paper are as follows: (a) LLMs are 3-6 times more likely to choose an occupation that stereotypically aligns with a person's gender; (b) these choices align with people's perceptions better than with the ground truth as reflected in official job statistics; (c) LLMs in fact amplify the bias beyond what is reflected in perceptions or the ground truth; (d) LLMs ignore crucial ambiguities in sentence structure 95% of the time in our study items, but when explicitly prompted, they recognize the ambiguity; (e) LLMs provide explanations for their choices that are factually inaccurate and likely obscure the true reason behind their predictions."
  },
  "adjectives?": {
    "https://openalex.org/W217153343": "Many English adjectives form the comparative in two ways, so that, for instance, prouder occurs alongside more proud . We focus on four English morphosyntactic variables that problematize assumptions about the nature of variation in the vernacular: the genitive, the comparative, the dative, and relative pronouns. Some English adjectives accept both synthetic and analytic comparative and superlative forms (e.g. As many as 20+ variables have been claimed to affect this choice (see Leech &amp; Culpeper 1997; Lindquist 2000; Mondorf 2003, 2009). There has been no lack of research on the variation of comparative adjective forms in contemporary English, but our understanding of comparison strategies is still limited, with respect to individual patterns of adjectives, as well as sociolinguistic factors (e.g. This article presents a quantitative investigation of selected disyllabic adjectives in comparison (i.e. ample, bitter, common, complete, costly, deadly, empty, friendly, kindly, likely, obscure, remote, robust, severe, simple, sober, wealthy), based on the 2001\u20132005 issues of two different types of newspapers in British English (i.e. costlier and more costly, respectively), these factors do not affect all adjectives equally. We also found that, for many adjectives, periphrastic comparison is more likely to be preferred in the less formal newspaper (i.e. The present study also explores the strategies employed when selecting comparative forms for superlative adjectives and shows that factors which are influential on the comparative formation are not always effective on the superlative comparison. &lt;p&gt;There are two main ways of expressing the comparative in English adjectives. For the group of adjectives ending in an orthographic -y and an /i/ sound, which I call the y-adjectives, the alternation between more and -er cannot be neatly explained by structural accounts, whether predominantly synchronic or diachronic. This paradigm comprises a multitude of more and -er constructions (including those of y-adjectives) that share the grammatical function of the comparative. The goal of this thesis is to examine to what extent the comparatives of y-adjectives can be accounted for by the comparative constructions of other members in this paradigm, in addition to a set of syntactic, morphological and phonological considerations. Two empirical studies are reported: a study of the comparative constructions in seven corpora of British comedies spanning the 17th to the 20th centuries; and an experimental study where reading times in the context of comparative y-adjective constructions were observed in a series of self-paced reading tasks. Additionally, significant correlations are found between: \u2022 the comparatives of y-adjectives and those of the disyllabic adjectives that are not y-adjectives (to which I have given the cover term of HANDSOME adjectives); \u2022 the comparatives of y-adjectives and those of the monosyllabic adjectives; and \u2022 the comparatives of y-adjectives and those of adverbs that share some formal features with y-adjectives. The experimental study furthers an investigation of comparative alternation in y-adjectives in terms of the comparatives of HANDSOME adjectives and the morphological structure of y-adjective bases. In this study, pre-to-post treatment reading is found to be facilitated in y-adjective more comparatives by an exposure to multiple instances of more constructions from the HANDSOME adjectives. The more constructions from HANDSOME adjectives are also found to reduce facilitation in reading in morphologically simple y-adjectives paired with -er. On the other hand, the -er constructions from HANDSOME adjectives are found to reduce facilitation in reading in morphologically complex y-adjectives paired with more. The studies undertaken in this work indicate two important predictors of the comparatives of y-adjectives: the comparatives of HANDSOME adjectives; and the morphological structure of y-adjective bases. The involvement of the comparatives of HANDSOME adjectives as a predictor points to the importance of a paradigm of comparatives for an understanding of the comparatives of y-adjectives. The influence of this paradigm, combined with the influence of morphology, is argued to shed light on a question motivated by the diachronic literature on what could be suppressing the susceptibility of y-adjectives to the structural motivators for particular comparatives. English adjective comparison is increasingly the focus of corpus linguistic research, but it is much less studied in the variationist framework. However, our understanding of the strategies for comparison comes from written genres. In contrast, very little is known about comparison in vernacular speech. Since periphrastic comparison emerged as a change from above, the lack of spoken evidence proves a critical gap in our knowledge. To address this gap, this paper examines comparison strategies in New Zealand English, drawing on the whole of the Origins of New Zealand English Archive (Gordon et al. Consistent with reports elsewhere, inflection is the preferred mode of comparison. Rather, across the history of this variety (speakers born 1851-1982), individual adjectives pattern one way (inflection) or the other (periphrasis); in speech, the form of comparison has consistently been lexically conditioned, and by extension, invariant. &lt;p&gt;There are two main ways of expressing the comparative in English adjectives. For the group of adjectives ending in an orthographic -y and an /i/ sound, which I call the y-adjectives, the alternation between more and -er cannot be neatly explained by structural accounts, whether predominantly synchronic or diachronic. This paradigm comprises a multitude of more and -er constructions (including those of y-adjectives) that share the grammatical function of the comparative. The goal of this thesis is to examine to what extent the comparatives of y-adjectives can be accounted for by the comparative constructions of other members in this paradigm, in addition to a set of syntactic, morphological and phonological considerations. Two empirical studies are reported: a study of the comparative constructions in seven corpora of British comedies spanning the 17th to the 20th centuries; and an experimental study where reading times in the context of comparative y-adjective constructions were observed in a series of self-paced reading tasks. Additionally, significant correlations are found between: \u2022 the comparatives of y-adjectives and those of the disyllabic adjectives that are not y-adjectives (to which I have given the cover term of HANDSOME adjectives); \u2022 the comparatives of y-adjectives and those of the monosyllabic adjectives; and \u2022 the comparatives of y-adjectives and those of adverbs that share some formal features with y-adjectives. The experimental study furthers an investigation of comparative alternation in y-adjectives in terms of the comparatives of HANDSOME adjectives and the morphological structure of y-adjective bases. In this study, pre-to-post treatment reading is found to be facilitated in y-adjective more comparatives by an exposure to multiple instances of more constructions from the HANDSOME adjectives. The more constructions from HANDSOME adjectives are also found to reduce facilitation in reading in morphologically simple y-adjectives paired with -er. On the other hand, the -er constructions from HANDSOME adjectives are found to reduce facilitation in reading in morphologically complex y-adjectives paired with more. The studies undertaken in this work indicate two important predictors of the comparatives of y-adjectives: the comparatives of HANDSOME adjectives; and the morphological structure of y-adjective bases. The involvement of the comparatives of HANDSOME adjectives as a predictor points to the importance of a paradigm of comparatives for an understanding of the comparatives of y-adjectives. The influence of this paradigm, combined with the influence of morphology, is argued to shed light on a question motivated by the diachronic literature on what could be suppressing the susceptibility of y-adjectives to the structural motivators for particular comparatives.",
    "https://openalex.org/W2046567002": "In this article we develop a semantic typology of gradable predicates, with special emphasis on deverbal adjectives. We further showthat the classification of an important subclass of adjectives within the typology is largely predictable. These correlations underscore the fact that gradability is characteristic not only of adjectives but also of verbs and nouns, and that scalar properties are shared by categorially distinct but derivationally related expressions. In this paper we develop a semantic typology of gradable predicates, with special emphasis on deverbal adjectives. We further show that the classification of adjectives within the typology is largely predictable. These correlations underscore the fact that gradability is characteristic not only of adjectives but also of verbs and nouns, and that scalar properties are shared by categorially distinct but derivationally-related expressions.\u2217 The main aim of the article is to discuss the results of a number of corpus investigations and experiments of degree meanings in general and of the modification of degree in particular, and to accommodate these results in a general and dynamic model of Lexical Meaning as Ontologies and Construals (LOC; Paradis 2005). The claims are that (i) degree is a boundedness configuration in conceptual space; (ii) degree modifiers operate on the degree structure of the meanings to which they apply through a construal of contextually motivated zone activation within conventionalized senses; (iii) nonconventionalized degree readings of form\u2013meaning pairings are invoked through implication by means of construals of metonymization between senses; and (iv) this process of metonymization is the mechanism through which change may or may not take place. Abstract The simplest form in which gradable adjectives are used\u2014positive constructions, like John is tall\u2014carry an additional semantic component, evaluativity, that is not part of the adjective\u2019s lexicalized meaning. The source of evaluativity has posed a challenge for semantic accounts of adjectives and adjectival constructions, which are tasked with explaining why the most basic use of gradable adjectives doesn\u2019t reflect its core meaning.",
    "https://openalex.org/W2136944077": "No verb encodes both manner and result simultaneously, a truth-conditional fact that Rappaport Hovav and Levin argue follows from how verb meanings are composed at the level of event structure. However, using evidence from scopal adverbs, we argue that when the meanings occur together, they are encoded in a single, undecomposable manner+result root at event structure. This fact validates complementarity as a fact about how many and what types of roots may occur in an event structure, though it also argues for a richer typology of roots than is typically assumed, including those encoding manner and result simultaneously. This paper presents corpus-based evidence for a typology of multidimensional adjectives, like for example, healthy and sick.The interpretation of the latter is sensitive to multiple dimensions, such as blood pressure, pulse, sugar, cancer, etc.The study investigated the frequency of exception phrases, which operate on an implicit universal quantifier over adjectival dimensions, as in healthy, except for a slight cold, and not sick, except for high cholesterol.On the emerging typology, adjectives classify by the way their dimensions are glued together to create a single, uniform interpretation.The default interpretation of adjectives such as healthy involves implicit universal quantification over dimensions (dimension conjunction), while that of adjectives such as sick involves existential quantification (dimension disjunction).In adjectives like intelligent, the force of quantification over dimensions is context relative.Moreover, the paper presents support to the hypotheses that antonym polarity and modifier distribution guide our choice of quantifiers over dimensions in different adjectives.Thus, this research sheds new light on the nature of negative antonymy in multidimensional adjectives, and on the distribution of degree modifiers and exception phrases among multidimensional antonyms.Finally, it raises new questions pertaining to multidimensional comparisons. Part II discusses how children learn the form and meaning of words in their native language drawing from the key domains of phonology, morphology, syntax, semantics, and pragmatics. The empirical focus is the use of unmodified (positive form) gradable adjectives (GAs) in definite descriptions to distinguish between two objects that differ in the degree to which they possess the property named by the adjective. Bolstered by adult participant responses, this work provides important experimental support for theoretical claims regarding the semantics of gradable predicates and the nature of different types of 'interpretive variability', specifically semantic context dependence v.",
    "https://openalex.org/W2109688847": "Distributional semantics provides multi-dimensional, graded, empirically induced word representations that successfully capture many aspects of meaning in natural languages, as shown in a large body of work in computational linguistics; yet, its impact in theoretical linguistics has so far been limited. This review provides a critical discussion of the literature on distributional semantics, with an emphasis on methods and results that are of relevance for theoretical linguistics, in three areas: semantic change, polysemy and composition, and the grammar-semantics interface (specifically, the interface of semantics with syntax and with derivational morphology). Each cluster is intended to represent a different meaning of the input query, thus taking into account the lexical ambiguity (i.e., polysemy) issue. Key to our approach is to first acquire the various senses (i.e., meanings) of an ambiguous query and then cluster the search results based on their semantic similarity to the word senses induced. Experimenting with two context settings (a simple windowbased model and a \u2018co-disambiguation model\u2019 to approximate adjective sense disambiguation), our best model significantly outperforms the 50% baseline and achieves 70.6% accuracy in a synonym/antonym classification task. Many types of polysemy are not word specific, but are instances of general sense alternations such as ANIMAL-FOOD. Despite their pervasiveness, regular alternations have been mostly ignored in empirical computational semantics. One of the central problems in the semantics of derived words is polysemy (see, for example, the recent contributions by Lieber 2016 and Plag et al. In this paper, we tackle the problem of disambiguating newly derived words in context by applying Distributional Semantics ( Firth 1957 ) to deverbal -ment nominalizations (e.g. Furthermore, disambiguating low-frequency words presents an especially difficult task because there is little to no prior knowledge about these words from which their semantic properties can be extrapolated. Our question then was to what extent, and under which conditions, context-derived representations such as those of Distributional Semantics can be successfully employed in the disambiguation of low-frequency derivatives. We present indirect evidence that this is due to the semantic similarity of abstract non-eventive nouns to eventive nouns. Overall, this paper demonstrates that distributional semantic models can be fruitfully employed for the disambiguation of low frequency words in spite of the scarcity of available contextual information. Building on existing categorical accounts of natural language semantics, we propose a compositional distributional model of ambiguous meaning. Pushing the analogy with quantum mechanics further, we describe ambiguous words as statistical ensembles of unambiguous concepts and extend the semantics of the previous model to a category that supports probabilistic mixing. Abstract Polysemy is the type of lexical ambiguity where a word has multiple distinct but related interpretations. In the past decade, it has been the subject of a great many studies across multiple disciplines including linguistics, psychology, neuroscience, and computational linguistics, which have made it increasingly clear that the complexity of polysemy precludes simple, universal answers, especially concerning the representation and processing of polysemous words. But fuelled by the growing availability of large, crowdsourced datasets providing substantial empirical evidence; improved behavioral methodology; and the development of contextualized language models capable of encoding the fine-grained meaning of a word within a given context, the literature on polysemy recently has developed more complex theoretical analyses. In this survey we discuss these recent contributions to the investigation of polysemy against the backdrop of a long legacy of research across multiple decades and disciplines. Our aim is to bring together different perspectives to achieve a more complete picture of the heterogeneity and complexity of the phenomenon of polysemy. Our literature review finds that (i) traditional analyses of polysemy can be limited in their generalizability by loose definitions and selective materials; (ii) linguistic tests provide useful evidence on individual cases, but fail to capture the full range of factors involved in the processing of polysemous sense extensions; and (iii) recent behavioral (psycho) linguistics studies, large-scale annotation efforts, and investigations leveraging contextualized language models provide accumulating evidence suggesting that polysemous sense similarity covers a wide spectrum between identity of sense and homonymy-like unrelatedness of meaning. We hope that the interdisciplinary account of polysemy provided in this survey inspires further fundamental research on the nature of polysemy and better equips applied research to deal with the complexity surrounding the phenomenon, for example, by enabling the development of benchmarks and testing paradigms for large language models informed by a greater portion of the rich evidence on the phenomenon currently available.",
    "https://openalex.org/W189529527": "As the diversity in descriptive labels suggests, most previous work has taken these classes to embody distinct phenomena and to have distinct lexical semantic analyses. We claim that such \u201cmeasures of change\u201d are based on the more general kinds of measure functions that are lexicalized in many languages by gradable adjectives, and that map an object to a scalar value that represents the degree to which it manifests some gradable property at a time (see Bartsch and Vennemann 1972, 1973; Bierwisch 1989; Kennedy 1999b; Pinon 2005). As verbs for the most part derived from gradable adjectives, they most transparently illustrate the semantic components that we claim are involved in determining variable telicity. This paper presents corpus-based evidence for a typology of multidimensional adjectives, like for example, healthy and sick.The interpretation of the latter is sensitive to multiple dimensions, such as blood pressure, pulse, sugar, cancer, etc.The study investigated the frequency of exception phrases, which operate on an implicit universal quantifier over adjectival dimensions, as in healthy, except for a slight cold, and not sick, except for high cholesterol.On the emerging typology, adjectives classify by the way their dimensions are glued together to create a single, uniform interpretation.The default interpretation of adjectives such as healthy involves implicit universal quantification over dimensions (dimension conjunction), while that of adjectives such as sick involves existential quantification (dimension disjunction).In adjectives like intelligent, the force of quantification over dimensions is context relative.Moreover, the paper presents support to the hypotheses that antonym polarity and modifier distribution guide our choice of quantifiers over dimensions in different adjectives.Thus, this research sheds new light on the nature of negative antonymy in multidimensional adjectives, and on the distribution of degree modifiers and exception phrases among multidimensional antonyms.Finally, it raises new questions pertaining to multidimensional comparisons. The claims are that (i) degree is a boundedness configuration in conceptual space; (ii) degree modifiers operate on the degree structure of the meanings to which they apply through a construal of contextually motivated zone activation within conventionalized senses; (iii) nonconventionalized degree readings of form\u2013meaning pairings are invoked through implication by means of construals of metonymization between senses; and (iv) this process of metonymization is the mechanism through which change may or may not take place."
  },
  "What's an embedding?": {
    "https://openalex.org/W2807140737": "This paper takes a step towards theoretical analysis of the relationship between word embeddings and context embeddings in models such as word2vec. As a direct application of our result, we suggest a theoretically grounded way of tying weights in the SGNS model. Our methods improve the vanilla embeddings on all of word similarity tasks without any external resources. This paper takes a step towards the theoretical analysis of the relationship between word embeddings and context embeddings in models such as word2vec. As a direct application of our result, we suggest a theoretically grounded way of tying weights in the SGNS model.",
    "https://openalex.org/W4390873448": "While several metrics have been proposed to assess the rendering of images, it is crucial for Text-to-Image (T2I) models, which generate images based on a prompt, to consider additional aspects such as to which extent the generated image matches the important content of the prompt. We conducted a study on several recent T2I models about various aspects.",
    "https://openalex.org/W4386536278": "Abstract Graph neural networks (GNNs) have emerged as a powerful tool in graph representation learning. However, they are increasingly challenged by over-smoothing as network depth grows, compromising their ability to capture and represent complex graph structures. Additionally, some popular GNN variants only consider local neighbor information during node updating, ignoring the global structural information and leading to inadequate learning and differentiation of graph structures. To address these challenges, we introduce a novel graph neural network framework, GraphSAGE++. Our model extracts the representation of the target node at each layer and then concatenates all layer weighted representations to obtain the final result. In addition, the strategies combining double aggregations with weighted concatenation are proposed, which significantly enhance the model\u2019s discernment and preservation of structural information. Empirical results on various datasets demonstrate that GraphSAGE++ excels in vertex classification, link prediction, and visualization tasks, surpassing existing methods in effectiveness. Variational Graph Autoencoders (VAGE) emerged as powerful graph representation learning methods with promising performance on graph analysis tasks. However, existing methods typically rely on Graph Convolutional Networks (GCN) to encode the attributes and topology of the original graph. This strategy makes it difficult to fully learn high-order neighborhood information, which weakens the capacity to learn higher-quality representations. To address the above issues, we propose the Multi-order Variational Graph Autoencoders (MoVGAE) with co-learning of first-order and high-order neighborhoods. GCN and Multi-order Graph Convolutional Networks (MoGCN) are utilized to generate the mean and variance for the variational autoencoders. Then, MoVGAE uses the mean and variance to calculate node representations. Specifically, this approach comprehensively encodes first-order and high-order information in the graph data. Finally, the decoder reconstructs the adjacency matrix by performing the inner product of the representations. Experiments with the proposed method were conducted on node classification, node clustering, and link prediction tasks on real-world graph datasets. Furthermore, the robustness analysis verifies that MoVGAE has obvious advantages in the processes of graph data with insufficient attributes and topology.",
    "https://openalex.org/W2913433659": "A surprising property of word vectors is that word analogies can often be solved with vector arithmetic. We provide a formal explanation of this phenomenon without making the strong assumptions that past theories have made about the vector space and word distribution. We provide novel justification for the addition of SGNS word vectors by showing that it automatically down-weights the more frequent word, as weighting schemes do ad hoc. Lastly, we offer an information theoretic interpretation of Euclidean distance in vector spaces, justifying its use in capturing word dissimilarity. We construct a self-attention-enhanced distributed representation learning model for learning PKG embeddings from raw customer activity data in an end-to-end fashion. Embeddings mapping high-dimensional discrete input to lower-dimensional continuous vector spaces have been widely adopted in machine learning applications as a way to capture domain semantics. Interviewing 13 embedding users across disciplines, we find comparing embeddings is a key task for deployment or downstream analysis but unfolds in a tedious fashion that poorly supports systematic exploration. Producing an overview of innovative companies in a country is a challenging task. Model stability, model bias, the minimal number of words extracted from a website and companies without a website were found to be important issues in producing high quality results. Hyperbolic embeddings have recently gained attention in machine learning due to their ability to represent hierarchical data more accurately and succinctly than their Euclidean analogues. Our Multi-Relational Poincare model (MuRP) learns relation-specific parameters to transform entity embeddings by Mobius matrix-vector multiplication and Mobius addition. Experiments on the hierarchical WN18RR knowledge graph show that our Poincare embeddings outperform their Euclidean counterpart and existing embedding methods on the link prediction task, particularly at lower dimensionality. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. Most of these approaches focus strictly on leveraging the co-occurrences of relationship word pairs within sentences. In this paper, we investigate the hypothesis that examples of a lexical relation in a corpus are fundamental to a neural word embedding\u2019s ability to complete analogies involving the relation. This finding enhances our understanding of neural word embeddings, showing that co-occurrence information of a particular semantic relation is not the main source of their structural regularity.",
    "https://openalex.org/W2995755016": "The main idea behind our method is to visualize a joint embedding of the query and key vectors used by transformer models to compute attention. Unlike previous attention visualization techniques, our approach enables the analysis of global patterns across multiple input sequences. We create an interactive visualization tool, AttentionViz (demo: http://attentionviz.com), based on these joint query-key embeddings, and use it to study attention mechanisms in both language and vision transformers. In this paper, we present LLM Comparator, a novel visual analytics tool for interactively analyzing results from automatic side-by-side evaluation. Abstract Over the past years, an increasing number of publications in information visualization, especially within the field of visual analytics, have mentioned the term \u201cembedding\u201d when describing the computational approach. Within this context, embeddings are usually (relatively) low\u2010dimensional, distributed representations of various data types (such as texts or graphs), and since they have proven to be extremely useful for a variety of data analysis tasks across various disciplines and fields, they have become widely used. Existing visualization approaches aim to either support exploration and interpretation of the embedding space through visual representation and interaction, or aim to use embeddings as part of the computational pipeline for addressing downstream analytical tasks. To the best of our knowledge, this is the first survey that takes a detailed look at embedding methods through the lens of visual analytics, and the purpose of our survey article is to provide a systematic overview of the state of the art within the emerging field of embedding visualization. We design a categorization scheme for our approach, analyze the current research frontier based on peer\u2010reviewed publications, and discuss existing trends, challenges, and potential research directions for using embeddings in the context of visual analytics. Projecting high-dimensional vectors into two dimensions for visualization, known as embedding visualization, facilitates perceptual reasoning and interpretation. Comparison of multiple embedding visualizations drives decision-making in many domains, but conventional comparison methods are limited by a reliance on direct point correspondences. This requirement precludes embedding comparisons without point correspondences, such as two different datasets of annotated images, and fails to capture meaningful higher-level relationships among point groups. To address these shortcomings, we propose a general framework to compare embedding visualizations based on shared class labels rather than individual points. Our metrics enable more structured comparison through visual guidance and increased participants\u2019 confidence in their findings. In this work, we propose an interactive visual approach for the exploration and formation of structural relationships in embeddings of high-dimensional data. Nevertheless, most existing methods for the visual exploration of embeddings treat these structures as second-class citizens or do not take them into account at all. In our proposed analysis workflow, users explore enriched scatterplots of the embedding, in which relationships between items and/or groups are visually highlighted. The original high-dimensional data for single items, groups of items, or differences between connected items and groups is accessible through additional summary visualizations."
  },
  "tokens": {
    "https://openalex.org/W2509343702": "This paper describes an approach at Named Entity Recognition (NER) in German language documents from the legal domain. For this purpose, a dataset consisting of German court decisions was developed. The source texts were manually annotated with 19 semantic classes: person, judge, lawyer, country, city, street, landscape, organization, company, institution, court, brand, law, ordinance, European legal norm, regulation, contract, court decision, and legal literature. For the task of NER, Conditional Random Fields (CRFs) and bidirectional Long-Short Term Memory Networks (BiLSTMs) were applied to the dataset as state of the art models. This paper presents a case study on implementing a pipeline that provides German-speaking university students enrolled in an introductory-level educational psychology lecture with content-specific feedback for a lecture assignment. For this purpose, we implemented a natural language processing pipeline with two steps: (1) segmenting the essays and (2) predicting codes from the resulting segments used to generate feedback texts. Social movement organizations (SMOs) increasingly rely on Twitter to create new and viral communication spaces alongside newsworthy protest events and communicate their grievance directly to the public. We analyze the German-language Twitter communication of the climate movement Fridays for Future (FFF) before and during the lockdown to explain how SMOs adapted their strategy under online-only conditions. However, for low-resource languages like German, the use of modern text processing applications that require a large amount of training data proves to be difficult, as only few data sets are available mainly due to legal restrictions. With a general annotation scheme that can be used not only in the radiology field but also in a broader clinical setting, we contribute to a more consistent labeling and annotation process that also facilitates the verification and evaluation of language models in the German clinical setting. This paper describes the goals, design and results of a shared task on the automatic linguistic annotation of German language data from genres of computer-mediated communication (CMC), social media interactions and Web corpora.The two subtasks of tokenization and part-of-speech tagging were performed on two data sets: (i) a genuine CMC data set with samples from several CMC genres, and (ii) a Web corpora data set of CC-licensed Web pages which represents the type of data found in large corpora crawled from the Web.The teams participating in the shared task achieved a substantial improvement over current off-the-shelf tools for German.The best tokenizer reached an F 1score of 99.57% (vs.98.95% off-the-shelf baseline), while the best tagger reached an accuracy of 90.44% (vs.84.86% baseline).The gold standard (more than 20,000 tokens of training and test data) is freely available online together with detailed annotation guidelines. In this work, we address this research gap and conduct a bilingual study of privacy policies in English and German that investigates the effects of the GDPR and CCPA/CPRA on privacy policy content, using established methods from corpus linguistics that are language-independent and do not rely on keyword lists or classifiers that may date quickly. While companies outside California and the US did adapt their disclosures to the CCPA/CPRA, this was limited to English-language policies and did not spill over to policies in German. Texts obtained from web are noisy and do not necessarily follow the orthographic sentence and word boundary rules. Thus, sentence segmentation and word tokenization systems that have been developed on well-formed texts might not perform so well on unedited web texts. In this paper, we first describe the manual annotation of sentence boundaries of an Estonian web dataset and then present the evaluation results of three existing sentence segmentation and word tokenization systems on this corpus: EstNLTK, Stanza and UDPipe.",
    "https://openalex.org/W2037450062": "This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Tokenization is a fundamental preprocessing step for almost all NLP tasks. In this paper, we propose efficient algorithms for the WordPiece tokenization used in BERT, from single-word tokenization to general text (e.g., sentence) tokenization. We propose a novel algorithm whose tokenization complexity is strictly O(n). For general text, we further propose an algorithm that combines pre-tokenization (splitting the text into words) and our linear-time WordPiece method into a single pass. Experimental results show that our method is 8.2x faster than HuggingFace Tokenizers and 5.1x faster than TensorFlow Text on average for general text tokenization.",
    "https://openalex.org/W4206660322": "Until recently, most natural language processing (NLP) models operated over words, treating those as discrete and atomic tokens, but starting with byte-pair encoding (BPE), subword-based approaches have become dominant in many areas, enabling small vocabularies while still allowing for fast inference. We conclude that there is and likely will never be a silver bullet singular solution for all applications and that thinking seriously about tokenization remains important for many applications. These files are then passed through a pre-tokenization feature generator, and the resulting keywords are used to train the tokenizer from scratch.",
    "https://openalex.org/W2403707901": "We conduct a survey with 66 practitioners to assess if they agree with the identified defect categories included in our taxonomy. Based on the Lenses, SearchLens generates personalized interfaces with visual explanations that promotes transparency and enables deeper exploration. While prior work found searchers may not wish to put in effort specifying their goals without immediate and sufficient benefits, results from a controlled lab study suggest that our approach incentivized participants to express their interests more richly than in a baseline condition, and a field study showed that participants found benefits in SearchLens while conducting their own tasks. Average absolute vocabulary sizes ranged from 5900 lemmas in first grade to 73,000 for adults, with significant increases between adjacent grade levels except from first to second grade. We present a language-independent clausizer (clause splitter) based on Universal Dependencies (Nivre et al., 2016), and a clause-level tagger for grammatical tense, mood, voice and modality in German.The paper recapitulates verbal inflection in German-always juxtaposed with its close relative English-and transforms the linguistic theory into a rule-based algorithm.We achieve state-of-the-art accuracies of 92.6% for tense, 79.0% for mood, 93.8% for voice and 79.8% for modality in the literary domain. In this paper we describe SoMaJo, a rulebased tokenizer for German web and social media texts that was the best-performing system in the EmpiriST 2015 shared task with an average F 1 -score of 99.57.We give an overview of the system and the phenomena its rules cover, as well as a detailed error analysis.The tokenizer is available as free software. This paper describes the goals, design and results of a shared task on the automatic linguistic annotation of German language data from genres of computer-mediated communication (CMC), social media interactions and Web corpora.The two subtasks of tokenization and part-of-speech tagging were performed on two data sets: (i) a genuine CMC data set with samples from several CMC genres, and (ii) a Web corpora data set of CC-licensed Web pages which represents the type of data found in large corpora crawled from the Web.The teams participating in the shared task achieved a substantial improvement over current off-the-shelf tools for German.The best tokenizer reached an F 1score of 99.57% (vs.98.95% off-the-shelf baseline), while the best tagger reached an accuracy of 90.44% (vs.84.86% baseline).The gold standard (more than 20,000 tokens of training and test data) is freely available online together with detailed annotation guidelines."
  },
  "What are embeddings?": {
    "https://openalex.org/W4390873448": "While several metrics have been proposed to assess the rendering of images, it is crucial for Text-to-Image (T2I) models, which generate images based on a prompt, to consider additional aspects such as to which extent the generated image matches the important content of the prompt. We conducted a study on several recent T2I models about various aspects.",
    "https://openalex.org/W2807140737": "This paper takes a step towards theoretical analysis of the relationship between word embeddings and context embeddings in models such as word2vec. As a direct application of our result, we suggest a theoretically grounded way of tying weights in the SGNS model. Our methods improve the vanilla embeddings on all of word similarity tasks without any external resources. This paper takes a step towards the theoretical analysis of the relationship between word embeddings and context embeddings in models such as word2vec. As a direct application of our result, we suggest a theoretically grounded way of tying weights in the SGNS model.",
    "https://openalex.org/W2913433659": "A surprising property of word vectors is that word analogies can often be solved with vector arithmetic. We provide a formal explanation of this phenomenon without making the strong assumptions that past theories have made about the vector space and word distribution. We provide novel justification for the addition of SGNS word vectors by showing that it automatically down-weights the more frequent word, as weighting schemes do ad hoc. Lastly, we offer an information theoretic interpretation of Euclidean distance in vector spaces, justifying its use in capturing word dissimilarity. We construct a self-attention-enhanced distributed representation learning model for learning PKG embeddings from raw customer activity data in an end-to-end fashion. Embeddings mapping high-dimensional discrete input to lower-dimensional continuous vector spaces have been widely adopted in machine learning applications as a way to capture domain semantics. Interviewing 13 embedding users across disciplines, we find comparing embeddings is a key task for deployment or downstream analysis but unfolds in a tedious fashion that poorly supports systematic exploration. Producing an overview of innovative companies in a country is a challenging task. Model stability, model bias, the minimal number of words extracted from a website and companies without a website were found to be important issues in producing high quality results. Hyperbolic embeddings have recently gained attention in machine learning due to their ability to represent hierarchical data more accurately and succinctly than their Euclidean analogues. Our Multi-Relational Poincare model (MuRP) learns relation-specific parameters to transform entity embeddings by Mobius matrix-vector multiplication and Mobius addition. Experiments on the hierarchical WN18RR knowledge graph show that our Poincare embeddings outperform their Euclidean counterpart and existing embedding methods on the link prediction task, particularly at lower dimensionality. To predict whether a relation holds between entities, embeddings are typically compared in the latent space following a relation-specific mapping. Whilst their predictive performance has steadily improved, how such models capture the underlying latent structure of semantic information remains unexplained. Building on recent theoretical understanding of word embeddings, we categorise knowledge graph relations into three types and for each derive explicit requirements of their representations. Most of these approaches focus strictly on leveraging the co-occurrences of relationship word pairs within sentences. In this paper, we investigate the hypothesis that examples of a lexical relation in a corpus are fundamental to a neural word embedding\u2019s ability to complete analogies involving the relation. This finding enhances our understanding of neural word embeddings, showing that co-occurrence information of a particular semantic relation is not the main source of their structural regularity.",
    "https://openalex.org/W4288620981": "One of the most remarkable properties of word embeddings is the fact that they capture certain types of semantic and syntactic relationships. However, it is unclear to what extent such models capture relational knowledge beyond what is already captured by standard word embeddings. Finally, we fine-tune a language model to predict whether a given word pair is likely to be an instance of some relation, when given an instantiated template for that relation as input. A surprising property of word vectors is that word analogies can often be solved with vector arithmetic. We provide a formal explanation of this phenomenon without making the strong assumptions that past theories have made about the vector space and word distribution. We provide novel justification for the addition of SGNS word vectors by showing that it automatically down-weights the more frequent word, as weighting schemes do ad hoc. Lastly, we offer an information theoretic interpretation of Euclidean distance in vector spaces, justifying its use in capturing word dissimilarity. We construct a self-attention-enhanced distributed representation learning model for learning PKG embeddings from raw customer activity data in an end-to-end fashion. While there has been a recent explosion of work on ExplainableAI ExAI on deep models that operate on imagery and tabular data, textual datasets present new challenges to the ExAI community. Such challenges can be attributed to the lack of input structure in textual data, the use of word embeddings that add to the opacity of the models and the difficulty of the visualization of the inner workings of deep models when they are trained on textual data. Lately, methods have been developed to address the aforementioned challenges and present satisfactory explanations on Natural Language Processing (NLP) models. However, such methods are yet to be studied in a comprehensive framework where common challenges are properly stated and rigorous evaluation practices and metrics are proposed. We make this distinction and we further decompose the methods into three categories according to what they explain: (1) word embeddings (input-level), (2) inner workings of NLP models (processing-level) and (3) models' decisions (output-level). We investigate compositional structures in data embeddings from pre-trained vision-language models (VLMs). Traditionally, compositionality has been associated with algebraic operations on embeddings of words from a preexisting vocabulary. These vectors can be seen as \"ideal words\" for generating concepts directly within embedding space of the model. We first present a framework for understanding compositional structures from a geometric perspective. We then explain what these compositional structures entail probabilistically in the case of VLM embeddings, providing intuitions for why they arise in practice. Finally, we empirically explore these structures in CLIP's embeddings and we evaluate their usefulness for solving different vision-language tasks such as classification, debiasing, and retrieval.",
    "https://openalex.org/W2787481916": "This survey focuses on the representation of meaning. We start from the theoretical background behind word vector space models and highlight one of their major limitations: the meaning conflation deficiency, which arises from representing a word with all its possible meanings as a single vector. Then, we explain how this deficiency can be addressed through a transition from the word level to the more fine-grained level of word senses (in its broader acceptation) as a method for modelling unambiguous lexical meaning. Finally, this survey covers the main evaluation procedures and applications for this type of representation, and provides an analysis of four of its important aspects: interpretability, sense granularity, adaptability to different domains and compositionality.&#x0D; &#x0D; &#x0D; Extensive evaluation on a large number of word embedding models for language processing applications is conducted in this work.First, we introduce popular word embedding models and discuss desired properties of word models and evaluation methods (or evaluators).Then, we categorize evaluators into intrinsic and extrinsic two types.Intrinsic evaluators test the quality of a representation independent of specific natural language processing tasks while extrinsic evaluators use word embeddings as input features to a downstream task and measure changes in performance metrics specific to that task.We report experimental results of intrinsic and extrinsic evaluators on six word embedding models.It is shown that different evaluators focus on different aspects of word models, and some are more correlated with natural language processing tasks.Finally, we adopt correlation analysis to study performance consistency of extrinsic and intrinsic evaluators. While one of the first steps in many NLP systems is selecting what pre-trained word embeddings to use, we argue that such a step is better left for neural networks to figure out by themselves. To that end, we introduce dynamic meta-embeddings, a simple yet effective method for the supervised learning of embedding ensembles, which leads to state-of-the-art performance within the same model class on a variety of tasks. We subsequently show how the technique can be used to shed new light on the usage of word embeddings in NLP systems. Despite the fast developmental pace of new sentence embedding methods, it is still challenging to find comprehensive evaluations of these different techniques. In the past years, we saw significant improvements in the field of sentence embeddings and especially towards the development of universal sentence encoders that could provide inductive transfer to a wide variety of downstream tasks. In this work, we perform a comprehensive evaluation of recent methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets. In this article, we present a survey that analyzes these efforts. Word embedding models have gained a lot of traction in the Natural Language Processing community, however, they suffer from unintended demographic biases. Most approaches to evaluate these biases rely on vector space based metrics like the Word Embedding Association Test (WEAT). While these approaches offer great geometric insights into unintended biases in the embedding vector space, they fail to offer an interpretable meaning for how the embeddings could cause discrimination in downstream NLP applications. In this work, we present a transparent framework and metric for evaluating discrimination across protected groups with respect to their word embedding bias. Our metric (Relative Negative Sentiment Bias, RNSB) measures fairness in word embeddings via the relative negative sentiment associated with demographic identity terms from various protected groups. We show that our framework and metric enable useful analysis into the bias in word embeddings. An interesting method of evaluating word representations is by how much they reflect the semantic representations in the human brain. In this paper, we present the first multi-modal framework for evaluating English word representations based on cognitive lexical semantics. Six types of word embeddings are evaluated by fitting them to 15 datasets of eye-tracking, EEG and fMRI signals recorded during language processing. To achieve a global score over all evaluation hypotheses, we apply statistical significance testing accounting for the multiple comparisons problem. This framework is easily extensible and available to include other intrinsic and extrinsic evaluation methods. D-GEF operates on a Graph-of-Words (GoW) representation of hacker forum text to generate word embeddings in an unsupervised manner. A series of benchmark experiments illustrate D-GEF's ability to generate higher quality than state-of-the-art word embedding models (e.g., word2vec) in tasks pertaining to semantic analogy, clustering, and threat classification."
  },
  "What is a giraffe?": {},
  "Can we model how languages evolve computationlly?": {
    "https://openalex.org/W2313740072": "Cognitive linguists and psychologists have often argued that language is best understood as an association network; however while the network view of language has had a significant impact on the study of morphology and lexical semantics, it is only recently that researchers have taken an explicit network approach to the study of syntax. These associations are shaped by domain-general learning processes that are operative in language use and sensitive to frequency of occurrence. Drawing on research from usage-based linguistics and cognitive psychology, the book provides an overview of frequency effects in grammar and analyzes these effects within the framework of a dynamic network model. Cognitive linguists and psychologists have often argued that language is best understood as an association network; however while the network view of language has had a significant impact on the study of morphology and lexical semantics, it is only recently that researchers have taken an explicit network approach to the study of syntax. These associations are shaped by domain-general learning processes that are operative in language use and sensitive to frequency of occurrence. Drawing on research from usage-based linguistics and cognitive psychology, the book provides an overview of frequency effects in grammar and analyzes these effects within the framework of a dynamic network model. A growing number of studies on language change adopt Construction Grammar as a theoretical framework so that there is now a developing field of Diachronic Construction Grammar. These three questions pertain to the status of constructions as mental representations of language, the emergence of new constructions, and the way in which nodes and connections are viewed as parts of the constructional network. guistic categories.Here, the agents are capable of inventing grammatical markers for indicating event structure relations, and of generalizing those markers to semantic roles by performing analogical reasoning over events.Extension by analogy occurs as a side-effect of the need to optimize communicative success.In the second experiment, agents are capable of combining case markers into larger argument structure constructions through pattern formation.The results show that languages become unsystematic if the linguistic inventory is unstructured and contains multiple levels of organization.This book demonstrates that this problem of systematicity can be solved through multilevel alignment.All the experiments are implemented in Fluid Construction Grammar (FCG), and use the first computational formalization of argument structure in a construction-based approach that works for both production and parsing.Even though the experiments involve the formation of artificial languages, the results are highly relevant for natural language research as well.This book therefore engages in an interdisciplinary dialogue with linguistics and contributes to some currently ongoing debates such as the formalization of argument structure in construction grammar, the organization of the linguistic inventory, the status of semantic maps and thematic hierarchies and the mechanisms for explaining grammaticalization.x 1 Case and artificial language evolution event-specific participant role (move -movermoved) Usage-based linguists and psychologists have produced a large body of empirical results suggesting that linguistic structure is derived from language use. These associations are shaped by domain-general processes that can give rise to new structures and meanings in language acquisition and language change. Combining research from linguistics and psychology, the paper proposes specific network analyses for the following phenomena: argument structure, word classes, constituent structure, constructions and construction families, and grammatical categories such as voice, case and number. How Linguistic Structure is Shaped by Language Use ) but approaches the topic from a different perspective. Abstract Vocabulary acquisition is a critical part of learning a new language. Yet, due to structural, historical, and individual variability associated with natural languages, isolating the impact of specific factors on word learning can be challenging. Artificial languages are versatile tools for addressing this problem, allowing researchers to systematically manipulate properties of the language and control for learners\u2019 past experiences. Here, we review how artificial languages have been used to study bilingual word learning, with a particular focus on the influences of language input (e.g., word properties) and language experience (e.g., bilingualism). We additionally discuss the advantages and limitations of artificial languages for bilingual research and suggest resources for researchers considering the use of artificial languages. Used and interpreted properly, artificial language studies can inform our understanding of a wide range of factors relevant to word learning. Language change is increasingly recognized as one of the most crucial sources of evidence for understanding human cognition. Unfortunately, despite sophisticated methods for documenting which changes have taken place, the question of why languages evolve over time remains open for speculation. This paper presents a novel research method that addresses this issue by combining agent-based experiments with deep language processing, and demonstrates the approach through a case study on German definite articles. The experiments show that inefficiencies detected in the grammar by the Old High German agents correspond to grammatical forms that have actually undergone the most important changes in the German language. The results thus suggest that the question of language change can be reformulated as an optimization problem in which language users try to achieve their communicative goals while allocating their cognitive resources as efficiently as possible.",
    "https://openalex.org/W2129085023": "This position paper proposes that the study of embodied cognitive agents, such as humanoid robots, can advance our understanding of the cognitive development of complex sensorimotor, linguistic, and social learning skills. These milestones provide a possible set of cognitive robotics goals and test scenarios, thus acting as a research roadmap for future work on cognitive developmental robotics. This book, intended primarily for researchers and advanced students, expands greatly on previous work by the authors exploring the topography of the multidimensional \"functional-cognitive space\" within which functional, cognitive and/or constructionist approaches to language can be located. Fluid Construction Grammar (FCG) is a new linguistic formalism designed to explore in how far a construction grammar approach can be used for handling open-ended grounded dialogue, i.e. We question whether Adele Goldberg fulfills her self-declared goal in \u201cConstructions at Work\u201d, i.e. We point out converging trends in computational linguistics that suggest formalizations of Construction Grammar. In particular, we go into recent developments in Data-Oriented Parsing, such as U-DOP and LFG-DOP, that produce an unlimited number of new utterances based on a finite number of stored form-meaning pairs. This chapter considers the application of the principles of Construction Grammar to language change. It describes a particular change in a morphological construction of Old Czech and discusses some of the ways in which constructions may change internally. The chapter explains the concept of constructionalization and establishes its connection with Construction Grammar. It highlights the gradual nature of constructional change, the micro-steps involved at different constructional levels, and the importance of context."
  },
  "Is there a relationship between gender bias and LLM alignment issues?": {
    "https://openalex.org/W4386302153": "Biases in medical artificial intelligence (AI) arise and compound throughout the AI lifecycle. These biases can have significant clinical consequences, especially in applications that involve clinical decision-making. Left unaddressed, biased medical AI can lead to substandard clinical decisions and the perpetuation and exacerbation of longstanding healthcare disparities. We discuss potential biases that can arise at different stages in the AI development pipeline and how they can affect AI algorithms and clinical decision-making. Bias can occur in data features and labels, model development and evaluation, deployment, and publication. Missing patient findings can also produce biased model behavior, including capturable but nonrandomly missing data, such as diagnosis codes, and data that is not usually or not easily captured, such as social determinants of health. Expertly annotated labels used to train supervised learning models may reflect implicit cognitive biases or substandard care practices. Overreliance on performance metrics during model development may obscure bias and diminish a model's clinical utility. How end users interact with deployed solutions can introduce bias. Finally, where models are developed and published, and by whom, impacts the trajectories and priorities of future medical AI development. Solutions to mitigate bias must be implemented with care, which include the collection of large and diverse data sets, statistical debiasing methods, thorough model evaluation, emphasis on model interpretability, and standardized bias reporting and transparency requirements. Prior to real-world implementation in clinical settings, rigorous validation through clinical trials is critical to demonstrate unbiased application. Addressing biases across model development stages is crucial for ensuring all patients benefit equitably from the future of medical AI. Abstract The paper aims to fulfil three main functions: (1) to serve as an introduction for the physics education community to the functioning of large language models (LLMs), (2) to present a series of illustrative examples demonstrating how prompt-engineering techniques can impact LLMs performance on conceptual physics tasks and (3) to discuss potential implications of the understanding of LLMs and prompt engineering for physics teaching and learning. As a side note, our results suggest that with ChatGPT-4, the size of large language models has reached a plateau. In conclusion, while large language models have revolutionised content generation, their ability to produce original scientific contributions in the humanities remains limited. We expect this to change in the near future as current large language model-based AI chatbots evolve into large language model-powered software. Large language models (LLMs) are increasingly capable of providing users with advice in a wide range of professional domains, including legal advice. In Study 3 (Data Generator), both models consistently replicated patterns of cultural bias previously discovered in large language corpora, indicating that ChatGPT can simulate known results, an antecedent to usefulness for both data generation and skills like hypothesis generation. Natural Language Processing Volume 6 - 2023 | https://doi.org/10.3389/frai.2023.1350306",
    "https://openalex.org/W4283162604": "Despite this success, these models can learn, perpetuate, and amplify harmful social biases. In this article, we present a comprehensive survey of bias evaluation and mitigation techniques for LLMs. We first consolidate, formalize, and expand notions of social bias and fairness in natural language processing, defining distinct facets of harm and introducing several desiderata to operationalize fairness for LLMs. We then unify the literature by proposing three intuitive taxonomies, two for bias evaluation, namely, metrics and datasets, and one for mitigation. Our first taxonomy of metrics for bias evaluation disambiguates the relationship between metrics and evaluation datasets, and organizes metrics by the different levels at which they operate in a model: embeddings, probabilities, and generated text. Our second taxonomy of datasets for bias evaluation categorizes datasets by their structure as counterfactual inputs or prompts, and identifies the targeted harms and social groups; we also release a consolidation of publicly available datasets for improved access. Our third taxonomy of techniques for bias mitigation classifies methods by their intervention during pre-processing, in-training, intra-processing, and post-processing, with granular subcategories that elucidate research trends. Synthesizing a wide range of recent research, we aim to provide a clear guide of the existing literature that empowers researchers and practitioners to better understand and prevent the propagation of bias in LLMs. However, computing research and practitioners lack a high level and synthesized overview of harms from algorithmic systems. Based on a scoping review of computing research (n=172), we present an applied taxonomy of sociotechnical harms to support a more systematic surfacing of potential harms in algorithmic systems. We conclude with a discussion of challenges and opportunities for future research. This paper presents a set of intersectional feminist principles for conducting equitable, ethical, and sustainable AI research. Here, we present a rationale for why feminism remains deeply relevant for AI research, rearticulate the original principles of data feminism with respect to AI, and introduce two potential new principles related to environmental impact and consent. Together, these principles help to 1) account for the unequal, undemocratic, extractive, and exclusionary forces at work in AI research, development, and deployment; 2) identify and mitigate predictable harms in advance of unsafe, discriminatory, or otherwise oppressive systems being released into the world; and 3) inspire creative, joyful, and collective ways to work towards a more equitable, sustainable world in which all of us can thrive. Most research on evaluating and mitigating fairness harms has been concentrated on English, while multilingual models and non-English languages have received comparatively little attention. This paper presents a survey of fairness in multilingual and non-English contexts, highlighting the shortcomings of current research and the difficulties faced by methods designed for English. Thus, the measurement and mitigation of biases must evolve beyond the current dataset-driven practices that are narrowly focused on specific dimensions and types of biases and, therefore, impossible to scale across languages and cultures. We present WinoQueer: a benchmark specifically designed to measure whether large language models (LLMs) encode biases that are harmful to the LGBTQ+ community. The benchmark is community-sourced, via application of a novel method that generates a bias benchmark from a community survey. We apply our benchmark to several popular LLMs and find that off-the-shelf models generally do exhibit considerable anti-queer bias. Finally, we show that LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community, and that social media text written by community members is more effective than news text written about the community by non-members. Our method for community-in-the-loop benchmark development provides a blueprint for future researchers to develop community-driven, harms-grounded LLM benchmarks for other marginalized communities. Bias detection in text is crucial for combating the spread of negative stereotypes, misinformation, and biased decision-making. Traditional language models frequently face challenges in generalizing beyond their training data and are typically designed for a single task, often focusing on bias detection at the sentence level. This model combines two complementary transformer networks: the context transformer and the entity transformer, with a focus on improving bias detection capabilities. We have prepared a dataset specifically for training these models to identify and locate biases in texts. Our evaluations across various datasets demonstrate CBDT effectiveness in distinguishing biased narratives from neutral ones and identifying specific biased terms. This work paves the way for applying the CBDT model in various linguistic and cultural contexts, enhancing its utility in bias detection efforts. We also make the annotated dataset available for research purposes. Information access research (and development) sometimes makes use of gender, whether to report on the demographics of participants in a user study, as inputs to personalized results or recommendations, or to make systems gender-fair, amongst other purposes. This work makes a variety of assumptions about gender, however, that are not necessarily aligned with current understandings of what gender is, how it should be encoded, and how a gender variable should be ethically used. In this work, we present a systematic review of papers on information retrieval and recommender systems that mention gender in order to document how gender is currently being used in this field. We find that most papers mentioning gender do not use an explicit gender variable, but most of those that do either focus on contextualizing results of model performance, personalizing a system based on assumptions of user gender, or auditing a model's behavior for fairness or other privacy-related issues. Moreover, most of the papers we review rely on a binary notion of gender, even if they acknowledge that gender cannot be split into two categories. We connect these findings with scholarship on gender theory and recent work on gender in human-computer interaction and natural language processing. We conclude by making recommendations for ethical and well-grounded use of gender in building and researching information access systems.",
    "https://openalex.org/W3195725782": "This paper chooses to focus specifically on the relationship between gender bias and AI, exploring claims of the neutrality of such technologies and how its understanding of bias could influence policy and outcomes. Building on a rich seam of literature from both technological and sociological fields, this article constructs an original framework through which to analyse both the perpetuation and mitigation of gender biases, choosing to categorize AI technologies based on whether their input is text or images. Through the close analysis and pairing of four case studies, the paper thus unites two often disparate approaches to the investigation of bias in technology, revealing the large and varied potential for AI to echo and even amplify existing human bias, while acknowledging the important role AI itself can play in reducing or reversing these effects. The conclusion calls for further collaboration between scholars from the worlds of technology, gender studies and public policy in fully exploring algorithmic accountability as well as in accurately and transparently exploring the potential consequences of the introduction of AI technologies. Representation Bias in data can happen due to various reasons ranging from historical discrimination to selection and sampling biases in the data acquisition and preparation methods. Given that \"bias in, bias out\", one cannot expect AI-based solutions to have equitable outcomes for societal applications, without addressing issues such as representation bias. While there has been extensive study of fairness in machine learning models, including several review papers, bias in the data has been less studied. This paper reviews the literature on identifying and resolving representation bias as a feature of a data set, independent of how consumed later. There is still a long way to fully address representation bias issues in data. The development of deep learning techniques has allowed Neural Machine Translation (NMT) models to become extremely powerful, given sufficient training data and training time. Automated systems that implement Machine learning (ML) and Artificial Intelligence (AI) algorithms present promising solutions to a variety of technological and non-technological issues. Recently, many of these systems are found to inherit and propagate gender and racial biases that disadvantages the minority population. In this paper, we analyze academic publications in the area of gender biases in ML and AI algorithms thus outlining different themes, mitigation and detection methods explored through research in this topic. Through a detailed analysis of N = 120 papers, we map the current research landscape on gender specific biases present in ML and AI assisted automated systems. We further point out the aspects of ML/AI gender biases research that are less explored and require more attention. We also shed some light into the gender bias issue as experienced by the algorithm designers. In conclusion, in this paper we provide a holistic view of the breadth of studies conducted in the field of exploring, detecting and mitigating gender biases in ML and AI systems and, a future direction for the studies to take in order to provide a fair and accessible ML and AI systems to all users. Abstract Measuring bias is key for better understanding and addressing unfairness in NLP/ML models. Next, we carry out an extensive empirical comparison of existing metrics and demonstrate that the observed differences in bias measurement can be systematically explained via differences in parameter choices for our generalized metrics. Like other machine learning technologies, speech and language technologies (re)produce structural oppression when they perform worse for marginalised language communities. Situating language technologies within the broader scholarship around algorithmic bias, consider the allocative and representational harms they can cause even (and perhaps especially) in systems which do not exhibit predictive bias, narrowly defined as differential performance between groups. This raises the question whether addressing or \"fixing\" this \"bias\" is actually always equivalent to mitigating the harms algorithmic systems can cause, in particular to marginalised communities. We showcase its potential by adopting it to highlight gender biases in machine translation models and locate factual knowledge inside GPT-2. Objective Artificial Intelligence (AI) has made significant inroads into various domains, including medicine, raising concerns about algorithmic bias. This study investigates the presence of biases in generative AI programs, with a specific focus on gender and racial representations across 19 medical residency specialties. Methodology This comparative study utilized DALL-E2 to generate faces representing 19 distinct residency training specialties, as identified by the Association of American Medical Colleges (AAMC), which were then compared to the AAMC's residency specialty breakdown with respect to race and gender. Results Our findings reveal an alignment between OpenAI's DALL-E2's predictions and the current demographic landscape of medical residents, suggesting an absence of algorithmic bias in this AI model. While AI excels at pattern recognition, it inherits and mirrors the biases present in its training data. To combat AI bias, addressing real-world disparities is imperative. Ultimately, our findings underscore the crucial role of real-world data quality in mitigating AI bias. As AI continues to shape healthcare and education, the pursuit of equitable, unbiased AI applications should remain at the forefront of these transformative endeavors.",
    "https://openalex.org/W2921633540": "GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. Technologies for abusive language detection are being developed and applied with little consideration of their potential biases. The results show evidence of systematic racial bias in all datasets, as classifiers trained on them tend to predict that tweets written in African-American English are abusive at substantially higher rates. However, there is ample evidence that they use the cultural biases that are undoubtedly present in the corpora they are trained on, implicitly creating harm with biased representations. CrowS-Pairs has 1508 examples that cover stereotypes dealing with nine types of bias, like race, religion, and age. The data focuses on stereotypes about historically disadvantaged groups and contrasts them with advantaged groups. We present the first challenge set and evaluation protocol for the analysis of gender bias in machine translation (MT). Our approach uses two recent coreference resolution datasets composed of English sentences which cast participants into non-stereotypical gender roles (e.g., \u201cThe doctor asked the nurse to help her in the operation\u201d). We devise an automatic gender bias evaluation method for eight target languages with grammatical gender, based on morphological analysis (e.g., the use of female inflection for the word \u201cdoctor\u201d). Our analyses show that four popular industrial MT systems and two recent state-of-the-art academic MT models are significantly prone to gender-biased translation errors for all tested target languages. Our data and code are publicly available at https://github.com/gabrielStanovsky/mt_gender."
  },
  "Cross-lingual embeddings": {
    "https://openalex.org/W2949359738": "Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons. We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from monolingual BERT models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries are automatically discovered and aligned during the joint training process. Recent advancement in KG embedding impels the advent of embedding-based entity alignment, which encodes entities in a continuous embedding space and measures entity similarities based on the learned embeddings. We survey 23 recent embedding-based entity alignment approaches and categorize them based on their techniques and characteristics. We develop an open-source library including 12 representative embedding-based entity alignment approaches, and extensively evaluate these approaches, to understand their strengths and limitations. Cross-lingual summarization is the task of generating a summary in one language given a text in a different language. Previous works on cross-lingual summarization mainly focus on using pipeline methods or training an end-to-end model using the translated parallel data. However, it is a big challenge for the model to directly learn cross-lingual summarization as it requires learning to understand different languages and learning how to summarize at the same time. In this paper, we propose to ease the cross-lingual summarization training by jointly learning to align and summarize. We design relevant loss functions to train this framework and propose several methods to enhance the isomorphism and cross-lingual transfer between languages. In addition, we show that our model even has the ability to generate cross-lingual summaries without access to any cross-lingual corpus. We find that performance rapidly deteriorates when source and target corpora are from different domains, and that random word embedding initialization can dramatically affect downstream translation performance. We present InstaMap, an instance-based method for learning projection-based cross-lingual word embeddings. InstaMap is a non-parametric model that learns a non-linear projection by iteratively: (1) finding a globally optimal rotation of the source embedding space relying on the Kabsch algorithm, and then (2) moving each point along an instance-specific translation vector estimated from the translation vectors of the point\u2019s nearest neighbours in the training dictionary. We report performance gains with InstaMap over four representative state-of-the-art projection-based models on bilingual lexicon induction across a set of 28 diverse language pairs. We note prominent improvements, especially for more distant language pairs (i.e., languages with non-isomorphic monolingual spaces). Existing algorithms for aligning cross-lingual word vector spaces assume that vector spaces are approximately isomorphic. In this work, we ask whether non-isomorphism is also crucially a sign of degenerate word vector spaces. We present a series of experiments across diverse languages which show that variance in performance across language pairs is not only due to typological differences, but can mostly be attributed to the size of the monolingual resources available, and to the properties and duration of monolingual training (e.g. Considering this character, we formulate sign language retrieval as a cross-lingual retrieval problem as well as a video-text retrieval task. Concretely, we take into account the linguistic properties of both sign languages and natural languages, and simultaneously identify the fine-grained cross-lingual (i.e., sign-to-word) mappings while contrasting the texts and the sign videos in a joint embedding space. This process is termed as cross-lingual contrastive learning. Our framework, termed as domain-aware sign language retrieval via Cross-lingual Contrastive learning or CiCo for short, outperforms the pioneering method by large margins on various datasets, e.g., +22.4 T2V and +28.0 V2T R@1 improvements on How2Sign dataset, and +13.7 T2V and +17.1 V2T R@1 improvements on PHOENIX-2014T dataset. Most of the successful and predominant methods for Bilingual Lexicon Induction (BLI) are mapping-based, where a linear mapping function is learned with the assumption that the word embedding spaces of different languages exhibit similar geometric structures (i.e. In this work, we propose a novel semi-supervised method to learn cross-lingual word embeddings for BLI.",
    "https://openalex.org/W3104723404": "The main goal behind state-of-the-art pre-trained multilingual models such as multilingual BERT and XLM-R is enabling and bootstrapping NLP applications in low-resource languages through zero-shot or few-shot cross-lingual transfer. In addition, we introduce a novel invertible adapter architecture and a strong baseline method for adapting a pre-trained multilingual model to a new language. MAD-X outperforms the state of the art in cross lingual transfer across a representative set of typologically diverse languages on named entity recognition and causal commonsense reasoning, and achieves competitive results on question answering. Much recent progress in applications of machine learning models to NLP has been driven by benchmarks that evaluate models across a wide variety of tasks. However, these broad-coverage benchmarks have been mostly limited to English, and despite an increasing interest in multilingual models, a benchmark that enables the comprehensive evaluation of such methods on a diverse range of languages and tasks is still missing. To this end, we introduce the Cross-lingual TRansfer Evaluation of Multilingual Encoders XTREME benchmark, a multi-task benchmark for evaluating the cross-lingual generalization capabilities of multilingual representations across 40 languages and 9 tasks. We demonstrate that while models tested on English reach human performance on many tasks, there is still a sizable gap in the performance of cross-lingually transferred models, particularly on syntactic and sentence retrieval tasks. There is also a wide spread of results across languages. We release the benchmark to encourage research on cross-lingual learning methods that transfer linguistic knowledge across a diverse and representative set of languages and tasks. This survey focuses on the representation of meaning. We start from the theoretical background behind word vector space models and highlight one of their major limitations: the meaning conflation deficiency, which arises from representing a word with all its possible meanings as a single vector. Then, we explain how this deficiency can be addressed through a transition from the word level to the more fine-grained level of word senses (in its broader acceptation) as a method for modelling unambiguous lexical meaning. Finally, this survey covers the main evaluation procedures and applications for this type of representation, and provides an analysis of four of its important aspects: interpretability, sense granularity, adaptability to different domains and compositionality.&#x0D; &#x0D; &#x0D; Unsupervised machine translation - i.e., not assuming any cross-lingual supervision signal, whether a dictionary, translations, or comparable corpora - seems impossible, but nevertheless, Lample et al. The model relies heavily on an adversarial, unsupervised cross-lingual word embedding technique for bilingual dictionary induction (Conneau et al., 2017), which we examine here. Our results identify the limitations of current unsupervised MT: unsupervised bilingual dictionary induction performs much worse on morphologically rich languages that are not dependent marking, when monolingual corpora from different domains or different embedding algorithms are used. We show that a simple trick, exploiting a weak supervision signal from identical words, enables more robust induction and establish a near-perfect correlation between unsupervised bilingual dictionary induction performance and a previously unexplored graph similarity metric. However, a systematic review of various ABSA tasks and their corresponding solutions is still lacking, which we aim to fill in this survey. From the perspective of solutions, we summarize the utilization of pre-trained language models for ABSA, which improved the performance of ABSA to a new stage. Besides, techniques for building more practical ABSA systems in cross-domain/lingual scenarios are discussed. Massively multilingual transformers (MMTs) pretrained via language modeling (e.g., mBERT, XLM-R) have become a default paradigm for zero-shot language transfer in NLP, offering unmatched transfer performance. In this work, we analyze the limitations of downstream language transfer with MMTs, showing that, much like cross-lingual word embeddings, they are substantially less effective in resource-lean scenarios and for distant languages. Most importantly, we demonstrate that the inexpensive few-shot transfer (i.e., additional fine-tuning on a few target-language instances) is surprisingly effective across the board, warranting more research efforts reaching beyond the limiting zero-shot conditions.",
    "https://openalex.org/W2626534681": "We introduce an architecture to learn joint multilingual sentence representations for 93 languages, belonging to more than 30 different families and written in 28 different scripts. This enables us to learn a classifier on top of the resulting embeddings using English annotated data only, and transfer it to any of the 93 languages without any modification. Our experiments in cross-lingual natural language inference (XNLI dataset), cross-lingual document classification (MLDoc dataset) and parallel corpus mining (BUCC dataset) show the effectiveness of our approach. We also introduce a new test set of aligned sentences in 112 languages, and show that our sentence embeddings obtain strong results in multilingual similarity search even for low-resource languages. Our implementation, the pre-trained encoder and the multilingual test set are available at https://github.com/facebookresearch/LASER We present an easy and efficient method to extend existing sentence embedding models to new languages. This allows to create multilingual versions from previously monolingual models. We use the original (monolingual) model to generate sentence embeddings for the source language and then train a new system on translated sentences to mimic the original model. Compared to other methods for training multilingual sentence embeddings, this approach has several advantages: It is easy to extend existing models with relatively few samples to new languages, it is easier to ensure desired properties for the vector space, and the hardware requirements for training are lower. Code to extend sentence embeddings models to more than 400 languages is publicly available. Cross-lingual or cross-domain correspondences play key roles in tasks ranging from machine translation to transfer learning. Recently, purely unsupervised methods operating on monolingual embeddings have become effective alignment tools. In this paper, we cast the correspondence problem directly as an optimal transport (OT) problem, building on the idea that word embeddings arise from metric recovery algorithms. Indeed, we exploit the Gromov-Wasserstein distance that measures how similarities between pairs of words relate across languages. Massively multilingual transformers (MMTs) pretrained via language modeling (e.g., mBERT, XLM-R) have become a default paradigm for zero-shot language transfer in NLP, offering unmatched transfer performance. In this work, we analyze the limitations of downstream language transfer with MMTs, showing that, much like cross-lingual word embeddings, they are substantially less effective in resource-lean scenarios and for distant languages. Most importantly, we demonstrate that the inexpensive few-shot transfer (i.e., additional fine-tuning on a few target-language instances) is surprisingly effective across the board, warranting more research efforts reaching beyond the limiting zero-shot conditions. Cross-lingual word embeddings (CLEs) facilitate cross-lingual transfer of NLP models. Despite their ubiquitous downstream usage, increasingly popular projection-based CLE models are almost exclusively evaluated on bilingual lexicon induction (BLI). Even the BLI evaluations vary greatly, hindering our ability to correctly interpret performance and properties of different CLE models. In this work, we take the first step towards a comprehensive evaluation of CLE models: we thoroughly evaluate both supervised and unsupervised CLE models, for a large number of language pairs, on BLI and three downstream tasks, providing new insights concerning the ability of cutting-edge CLE models to support cross-lingual NLP. We empirically demonstrate that the performance of CLE models largely depends on the task at hand and that optimizing CLE models for BLI may hurt downstream performance. We indicate the most robust supervised and unsupervised CLE models and emphasize the need to reassess simple baselines, which still display competitive performance across the board. The success of large pretrained language models (LMs) such as BERT and RoBERTa has sparked interest in probing their representations, in order to unveil what types of knowledge they implicitly capture. In this work, we present a systematic empirical analysis across six typologically diverse languages and five different lexical tasks, addressing the following questions: 1) How do different lexical knowledge extraction strategies (monolingual versus multilingual source LM, out-of-context versus in-context encoding, inclusion of special tokens, and layer-wise averaging) impact performance? How consistent are the observed effects across tasks and languages? 3) How do these representations fare against traditional static word vectors in lexical tasks 4) Does the lexical information emerging from independently trained monolingual LMs display latent similarities? Our main results indicate patterns and best practices that hold universally, but also point to prominent variations across languages and tasks. Moreover, we validate the claim that lower Transformer layers carry more type-level lexical knowledge, but also show that this knowledge is distributed across multiple layers. Linguistic typology aims to capture structural and semantic variation across the world\u2019s languages. A large-scale typology could provide excellent guidance for multilingual Natural Language Processing (NLP), particularly for languages that suffer from the lack of human labeled resources. We present an extensive literature survey on the use of typological information in the development of NLP techniques. Our survey demonstrates that to date, the use of information in existing typological databases has resulted in consistent but modest improvements in system performance. Recent work on bilingual lexicon induction (BLI) has frequently depended either on aligned bilingual lexicons or on distribution matching, often with an assumption about the isometry of the two spaces. We propose a technique to quantitatively estimate this assumption of the isometry between two embedding spaces and empirically show that this assumption weakens as the languages in question become increasingly etymologically distant. We then propose Bilingual Lexicon Induction with Semi-Supervision (BLISS) \u2014 a semi-supervised approach that relaxes the isometric assumption while leveraging both limited aligned bilingual lexicons and a larger set of unaligned word embeddings, as well as a novel hubness filtering technique. Our proposed method obtains state of the art results on 15 of 18 language pairs on the MUSE dataset, and does particularly well when the embedding spaces don\u2019t appear to be isometric. We introduce MULTI-EURLEX, a new multilingual dataset for topic classification of legal documents. We use the dataset as a testbed for zero-shot cross-lingual transfer, where we exploit annotated training documents in one language (source) to classify documents in another language (target). We find that fine-tuning a multilingually pretrained model (XLM-ROBERTA, MT5) in a single source language leads to catastrophic forgetting of multilingual knowledge and, consequently, poor zero-shot transfer to other languages. Adaptation strategies, namely partial fine-tuning, adapters, BITFIT, LNFIT, originally proposed to accelerate fine-tuning for new end-tasks, help retain multilingual knowledge from pretraining, substantially improving zero-shot cross-lingual transfer, but their impact also depends on the pretrained model used and the size of the label set.",
    "https://openalex.org/W2964266061": "We introduce an architecture to learn joint multilingual sentence representations for 93 languages, belonging to more than 30 different families and written in 28 different scripts. This enables us to learn a classifier on top of the resulting embeddings using English annotated data only, and transfer it to any of the 93 languages without any modification. Our experiments in cross-lingual natural language inference (XNLI dataset), cross-lingual document classification (MLDoc dataset) and parallel corpus mining (BUCC dataset) show the effectiveness of our approach. We also introduce a new test set of aligned sentences in 112 languages, and show that our sentence embeddings obtain strong results in multilingual similarity search even for low-resource languages. Our implementation, the pre-trained encoder and the multilingual test set are available at https://github.com/facebookresearch/LASER Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons. State-of-the-art unsupervised multilingual models (e.g., multilingual BERT) have been shown to generalize in a zero-shot cross-lingual setting. This generalization ability has been attributed to the use of a shared subword vocabulary and joint training across multiple languages giving rise to deep multilingual abstractions. We evaluate this hypothesis by designing an alternative approach that transfers a monolingual model to new languages at the lexical level. More concretely, we first train a transformer-based masked language model on one language, and transfer it to a new language by learning a new embedding matrix with the same masked language modeling objective, freezing parameters of all other layers. However, we show that it is competitive with multilingual BERT on standard cross-lingual classification benchmarks and on a new Cross-lingual Question Answering Dataset (XQuAD). Our results contradict common beliefs of the basis of the generalization ability of multilingual models and suggest that deep monolingual models learn some abstractions that generalize across languages. We also release XQuAD as a more comprehensive cross-lingual benchmark, which comprises 240 paragraphs and 1190 question-answer pairs from SQuAD v1.1 translated into ten languages by professional translators. We start from the theoretical background behind word vector space models and highlight one of their major limitations: the meaning conflation deficiency, which arises from representing a word with all its possible meanings as a single vector. Then, we explain how this deficiency can be addressed through a transition from the word level to the more fine-grained level of word senses (in its broader acceptation) as a method for modelling unambiguous lexical meaning. We present a comprehensive overview of the wide range of techniques in the two main branches of sense representation, i.e., unsupervised and knowledge-based. While modern machine translation has relied on large parallel corpora, a recent line of work has managed to train Neural Machine Translation (NMT) systems from monolingual corpora only (Artetxe et al., 2018c; Lample et al., 2018). Our method profits from the modular architecture of SMT: we first induce a phrase table from monolingual corpora through cross-lingual embedding mappings, combine it with an n-gram language model, and fine-tune hyperparameters through an unsupervised MERT variant. In addition, iterative backtranslation improves results further, yielding, for instance, 14.08 and 26.22 BLEU points in WMT 2014 English-German and English-French, respectively, an improvement of more than 7-10 BLEU points over previous unsupervised systems, and closing the gap with supervised SMT (Moses trained on Europarl) down to 2-5 BLEU points. Our implementation is available at https://github.com/artetxem/monoses Cross-lingual or cross-domain correspondences play key roles in tasks ranging from machine translation to transfer learning. Recently, purely unsupervised methods operating on monolingual embeddings have become effective alignment tools. Current state-of-the-art methods, however, involve multiple steps, including heuristic post-hoc refinement strategies. In this paper, we cast the correspondence problem directly as an optimal transport (OT) problem, building on the idea that word embeddings arise from metric recovery algorithms. Indeed, we exploit the Gromov-Wasserstein distance that measures how similarities between pairs of words relate across languages. We show that our OT objective can be estimated efficiently, requires little or no tuning, and results in performance comparable with the state-of-the-art in various unsupervised word translation tasks. Massively multilingual transformers (MMTs) pretrained via language modeling (e.g., mBERT, XLM-R) have become a default paradigm for zero-shot language transfer in NLP, offering unmatched transfer performance. In this work, we analyze the limitations of downstream language transfer with MMTs, showing that, much like cross-lingual word embeddings, they are substantially less effective in resource-lean scenarios and for distant languages. Most importantly, we demonstrate that the inexpensive few-shot transfer (i.e., additional fine-tuning on a few target-language instances) is surprisingly effective across the board, warranting more research efforts reaching beyond the limiting zero-shot conditions. Cross-lingual word embeddings (CLEs) facilitate cross-lingual transfer of NLP models. Despite their ubiquitous downstream usage, increasingly popular projection-based CLE models are almost exclusively evaluated on bilingual lexicon induction (BLI). In this work, we take the first step towards a comprehensive evaluation of CLE models: we thoroughly evaluate both supervised and unsupervised CLE models, for a large number of language pairs, on BLI and three downstream tasks, providing new insights concerning the ability of cutting-edge CLE models to support cross-lingual NLP. We indicate the most robust supervised and unsupervised CLE models and emphasize the need to reassess simple baselines, which still display competitive performance across the board. Viable cross-lingual transfer critically depends on the availability of parallel texts. Shortage of such resources imposes a development and evaluation bottleneck in multilingual processing. In this paper, we present the resource and showcase its utility in experiments with cross-lingual word embedding induction and multi-source part-of-speech projection.",
    "https://openalex.org/W3034402523": "Evaluation of cross-lingual encoders is usually performed either via zero-shot cross-lingual transfer in supervised downstream tasks or via unsupervised cross-lingual textual similarity. In this paper, we concern ourselves with reference-free machine translation (MT) evaluation where we directly compare source texts to (sometimes low-quality) system translations, which represents a natural adversarial setup for multilingual encoders. We systematically investigate a range of metrics based on state-of-the-art cross-lingual semantic representations obtained with pretrained M-BERT and LASER. We propose two partial remedies: (1) post-hoc re-alignment of the vector spaces and (2) coupling of semantic-similarity based metrics with target-side language modeling. In segment-level MT evaluation, our best metric surpasses reference-based BLEU by 5.7 correlation points. We present XHate-999, a multi-domain and multilingual evaluation data set for abusive language detection. By aligning test instances across six typologically diverse languages, XHate-999 for the first time allows for disentanglement of the domain transfer and language transfer effects in abusive language detection. We conduct a series of domain- and language-transfer experiments with state-of-the-art monolingual and multilingual transformer models, setting strong baseline results and profiling XHate-999 as a comprehensive evaluation resource for abusive language detection. Existing models for cross-domain named entity recognition (NER) rely on numerous unlabeled corpus or labeled NER training data in target domains.However, collecting data for low-resource target domains is not only expensive but also time-consuming.Hence, we propose a cross-domain NER model that does not use any external resources.We first introduce a Multi-Task Learning (MTL) by adding a new objective function to detect whether tokens are named entities or not.We then introduce a framework called Mixture of Entity Experts (MoEE) to improve the robustness for zero-resource domain adaptation.Finally, experimental results show that our model outperforms strong unsupervised cross-domain sequence labeling models, and the performance of our model is close to that of the state-of-theart model which leverages extensive resources. This work provides an extensive overview of existing methods and resources in multilingual ToD as an entry point to this exciting and emerging field. We find that the most critical factor preventing the creation of truly multilingual ToD systems is the lack of datasets in most languages for both training and evaluation. Hence, state-of-the-art approaches to multilingual ToD mostly rely on (zero- or few-shot) cross-lingual transfer from resource-rich languages (almost exclusively English), either by means of (i) machine translation or (ii) multilingual representations. These approaches are currently viable only for typologically similar languages and languages with parallel / monolingual corpora available. Finally, we list additional challenges that multilinguality poses for related areas (such as speech, fluency in generated text, and human-centred evaluation), and indicate future directions that hold promise to further expand language coverage and dialogue capabilities of current ToD systems. Word translation or bilingual lexicon induction (BLI) is a key cross-lingual task, aiming to bridge the lexical gap between different languages. At Stage C1, we propose to refine standard cross-lingual linear maps between static word embeddings (WEs) via a contrastive learning objective; we also show how to integrate it into the self-learning procedure for even more refined cross-lingual maps. Most Bilingual Lexicon Induction (BLI) methods retrieve word translation pairs by finding the closest target word for a given source word based on cross-lingual word embeddings (WEs). To address this problem, we propose a novel and effective method to improve translation pair retrieval in cross-lingual WEs. It demonstrates effectiveness and robustness across six experimental languages, including similar language pairs and distant language pairs, under both supervised and unsupervised settings. Effective projection-based cross-lingual word embedding (CLWE) induction critically relies on the iterative self-learning procedure. It gradually expands the initial small seed dictionary to learn improved cross-lingual mappings. In this work, we present ClassyMap, a classification-based approach to self-learning, yielding a more robust and a more effective induction of projection-based CLWEs. We show the benefits of ClassyMap for bilingual lexicon induction: we report consistent improvements in a weakly supervised setup (500 seed translation pairs) on a benchmark with 28 language pairs. In this work, we provide an extensive overview of existing efforts in multilingual ToD and analyse the factors preventing the development of truly multilingual ToD systems. We identify two main challenges that combined hinder the faster progress in multilingual ToD: (1) current state-of-the-art ToD models based on large pretrained neural language models are data hungry; at the same time (2) data acquisition for ToD use cases is expensive and tedious. Most existing approaches to multilingual ToD thus rely on (zero- or few-shot) cross-lingual transfer from resource-rich languages (in ToD, this is basically only English), either by means of (i) machine translation or (ii) multilingual representation spaces. However, such approaches are currently not a viable solution for a large number of low-resource languages without parallel data and/or limited monolingual corpora. Finally, we discuss critical challenges and potential solutions by drawing parallels between ToD and other cross-lingual and multilingual NLP research."
  },
  "I want to find parallel corpus resources.": {
    "https://openalex.org/W157432847": "In this article, we report on our work using the STRAND system for mining parallel text on the World Wide Web, first reviewing the original algorithm and results and then presenting a set of significant enhancements. These enhancements include the use of supervised learning based on structural features of documents to improve classification performance, a new content-based measure of translational equivalence, and adaptation of the system to take advantage of the Internet Archive for mining parallel text from the Web on a large scale. In this paper a robust, adaptive approach for mining parallel sentences from a bilingual comparable news collection is described Sentence length models and lexicon-based models are combined under a maximum likelihood criterion. Specific models are proposed to handle insertions and deletions that are frequent in bilingual data collected from the web. The proposed approach is adaptive, updating the translation lexicon iteratively using the mined parallel data to get better vocabulary coverage and translation probability parameter estimation. Experiments are carried out on 10 years of Xinhua bilingual news collection. Using the mined data, we get significant improvement in word-to-word alignment accuracy in machine translation modeling. This paper presents a new web mining scheme for parallel data acquisition.Based on the Document Object Model (DOM), a web page is represented as a DOM tree.Then a DOM tree alignment model is proposed to identify the translationally equivalent texts and hyperlinks between two parallel DOM trees.By tracing the identified parallel hyperlinks, parallel web documents are recursively mined.Compared with previous mining schemes, the benchmarks show that this new mining scheme improves the mining coverage, reduces mining bandwidth, and enhances the quality of mined parallel sentences. For the past 38 years the international conference Translating and the Computer has been a leading and distinctive forum for academics, users, developers and vendors of computer aids for translators and, increasingly, other translation technology tools.The event offers translators, interpreters, researchers and business people from translation companies, international organisations, universities and research labs, as well as freelance professionals the opportunity to discuss the latest developments and trends and exchange ideas.AsLing (International Association for Advancement in Language Technology), which took over the organisation of this conference in 2014, is proud to present the proceedings of Translating and the Computer 38 Conference (TC38), taking place in London on 17 and 18 November 2016.This year's conference continues the tradition of hosting quality speakers and panellists on a wide range of topics related to technology for translators and terminologists, as well as for interpreters.These range from translation tools, through machine translation, translation workflow, hybrid translation technologies, subtitling, terminology, standards and quality assessment.This year we are proud to continue the focus on the new technologies concerning interpreting where revolutionary changes are under way.We are confident that the e-proceedings featuring these contributions, accepted after a competitive reviewing process, will be an important reference and stimulus for future work.We are delighted to present our keynote speakers: Dieter Rummel and Henry Liu, representing respectively the by far largest and most complex translation service, The Directorate-General for Translation of the European Commission, and the world's premier professional organization for translators, FIT, the International Federation of Translators.We are also confident that you will find that all the presentations and posters, as well as the panels and workshops, will provide interesting user perspectives and opportunities for inspiring discussions. Word-sense disambiguation (WSD) is the process of identifying the meanings of words in context. This article begins with discussing the origins of the problem in the earliest machine translation systems. Early attempts to solve the WSD problem suffered from a lack of coverage. The main approaches to tackle the problem were dictionary-based, connectionist, and statistical strategies. \u2018Final\u2019 tasks produce results of use to those without a specific interest in language and often make use of \u2018intermediate\u2019 tasks. Abstract As the demand for global information increases significantly, multilingual corpora has become a valuable linguistic resource for applications to cross\u2010lingual information retrieval and natural language processing. However, the general\u2010purpose dictionary is less sensitive in both genre and domain. It is also impractical to manually construct tailored bilingual dictionaries or sophisticated multilingual thesauri for large applications. There are many domain\u2010specific parallel or comparable corpora that are employed in machine translation and cross\u2010lingual information retrieval. The objective of the present research is to construct English/Chinese parallel corpus automatically from the World Wide Web. In this paper, an alignment method is presented which is based on dynamic programming to identify the one\u2010to\u2010one Chinese and English title pairs. The method includes alignment at title level, word level and character level. As one word for a language may translate into two or more words repetitively in another language, the edit operation, deletion, is used to resolve redundancy. A score function is then proposed to determine the optimal title pairs. Experiments have been conducted to investigate the performance of the proposed method using the daily press release articles by the Hong Kong SAR government as the test bed. The release articles and speech articles, published by Hongkong &amp; Shanghai Banking Corporation Limited, are also used to test our method, the precision is 1.00, and the recall is 0.948. Aligned parallel corpora are an important resource for a wide range of multilingual researches, specifically, corpus-based machine translation. We propose a method of extracting sentence-level alignment by using an extended link-based bilingual lexicon method. Experimental results show that our method increase precision, while it reduce the total number of generated candidate pairs. In this article, we present a simple and effective approach for extracting bilingual lexicon from comparable corpora enhanced with parallel corpora. We make use of structural characteristics of the documents comprising the comparable corpus to extract parallel sentences with a high degree of quality. We then use state-of-the-art techniques to build a specialized bilingual lexicon from these sentences and evaluate the contribution of this lexicon when added to the comparable corpus-based alignment technique. We describe a set of techniques that have been developed while collecting parallel texts for Russian-English language pair and building a corpus of parallel sentences for training a statistical machine translation system. We discuss issues of verifying potential parallel texts and filtering out automatically translated documents. Finally we evaluate the quality of the 1-million-sentence corpus which we believe may be a useful resource for machine translation research. We present a general methodology for extracting multi-word expressions (of various types), along with their translations, from small parallel corpora. We automatically align the parallel corpus and focus on misalignments; these typically indicate expressions in the source language that are translated to the target in a non-compositional way. Evaluation of the quality of the extraction algorithm reveals significant improvements over naive alignment-based methods. External evaluation shows an improvement in the performance of machine translation that uses the extracted dictionary.",
    "https://openalex.org/W2047295649": "In the present study, we present different approaches for extraction of transliteration proper-noun pairs from parallel corpora based on different similarity measures between the English and romanized Arabic proper nouns under consideration. We evaluate the new approaches presented using two different English-Arabic parallel corpora. We present a novel method for discovering parallel sentences in comparable, non-parallel corpora. Using this approach, we extract parallel data from large Chinese, Arabic, and English non-parallel newspaper corpora. We also show that a good-quality MT system can be built from scratch by starting with a very small parallel corpus (100,000 words) and exploiting a large non-parallel corpus. The choice of natural language technology appropriate for a given language is greatly impacted by density (availability of digitally stored material).More than half of the world speaks medium density languages, yet many of the methods appropriate for high or low density languages yield suboptimal results when applied to the medium density case.In this paper we describe a general methodology for rapidly collecting, building, and aligning parallel corpora for medium density languages, illustrating our main points on the case of Hungarian, Romanian, and Slovenian.We also describe and evaluate the hybrid sentence alignment method we are using.",
    "https://openalex.org/W22168010": "The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. Our code is open-source, thread-safe, and integrated into the Moses, cdec, and Joshua translation systems. The paraphrases are extracted from bilingual parallel corpora totaling over 100 million sentence pairs and over 2 billion English words. Each paraphrase pair in PPDB contains a set of associated scores, including paraphrase probabilities derived from the bitext data and a variety of monolingual distributional similarity scores computed from the Google n-grams and the Annotated Gigaword corpus."
  }
}