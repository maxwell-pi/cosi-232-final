{
  "run_id": "17783e18-9cd3-430b-9423-4a8849d7e927",
  "timestamp": "2025-05-08T02-55-15.933755Z",
  "topic": "What are embeddings?",
  "seed_ids": [
    "https://openalex.org/W658020064"
  ],
  "bibliography": [
    {
      "id": "https://openalex.org/W4390873448",
      "title": "Linear Spaces of Meanings: Compositional Structures in Vision-Language Models",
      "authors": "Matthew Trager, Pramuditha Perera, Luca Zancato et al.",
      "year": 2023,
      "annotation": "Relevant.\n\nThe candidate paper is relevant to the topic of embeddings. Although the paper is more specifically focused on vision-language models (VLMs), it discusses the concept of data embeddings, which are a type of embedding. The paper explores the structures in these embeddings and how they can be used to generate concepts within the model's space. This relates to the general topic of embeddings as it provides an application and analysis of how embeddings work in a specific context.",
      "abstract": "We investigate compositional structures in data embeddings from pre-trained vision-language models (VLMs). Traditionally, compositionality has been associated with algebraic operations on of words a preexisting vocabulary. In contrast, we seek to approximate representations an encoder as combinations smaller set vectors the embedding space. These can be seen \"ideal words\" for generating concepts directly within space model. first present framework understanding geometric perspective. then explain what these entail probabilistically case VLM embeddings, providing intuitions why they arise practice. Finally, empirically explore CLIP's and evaluate their usefulness solving different tasks such classification, debiasing, retrieval. Our results show that simple linear used interpretable methods regulating behavior VLMs."
    },
    {
      "id": "https://openalex.org/W2807140737",
      "title": "What the Vec? Towards Probabilistically Grounded Embeddings",
      "authors": "Carl Allen, Ivana Bala\u017eevi\u0107, Timothy M. Hospedales",
      "year": 2018,
      "annotation": "The candidate paper is relevant to the intellectual context of the topic. The paper discusses word embeddings, a type of embedding used in natural language processing tasks. It specifically mentions Word2Vec and GloVe, which are popular word embedding algorithms. The paper also delves into the theoretical understanding of these embeddings, which directly relates to the topic of \"What are embeddings?\".",
      "abstract": "Word2Vec (W2V) and GloVe are popular, fast efficient word embedding algorithms. Their embeddings widely used perform well on a variety of natural language processing tasks. Moreover, W2V has recently been adopted in the field graph embedding, where it underpins several leading However, despite their ubiquity relatively simple model architecture, theoretical understanding what parameters learn why that is useful downstream tasks lacking. We show different interactions between PMI vectors reflect semantic relationships, such as similarity paraphrasing, encoded low dimensional under suitable projection, theoretically explaining work. As consequence, we also reveal an interesting mathematical interconnection considered relationships themselves."
    },
    {
      "id": "https://openalex.org/W2913433659",
      "title": "Analogies Explained: Towards Understanding Word Embeddings",
      "authors": "Carl Allen, Timothy M. Hospedales",
      "year": 2019,
      "annotation": "Relevant.\n\nThe candidate paper is relevant to the topic as it discusses word embeddings, a specific type of embeddings. Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation and are a key concept in the field of natural language processing. The paper further delves into the properties and behaviors of these embeddings, providing a deeper understanding of the topic.",
      "abstract": "Word embeddings generated by neural network methods such as word2vec (W2V) are well known to exhibit seemingly linear behaviour, e.g. the of analogy woman is queen man king approximately describe a parallelogram. This property particularly intriguing since not trained achieve it. Several explanations have been proposed, but each introduces assumptions that do hold in practice. We derive probabilistically grounded definition paraphrasing we re-interpret word transformation, mathematical description $w_x$ $w_y$. From these concepts prove existence relationships between W2V-type underlie analogical phenomenon, identifying explicit error terms."
    },
    {
      "id": "https://openalex.org/W4288620981",
      "title": "Analogies Explained: Towards Understanding Word Embeddings",
      "authors": "Carl E. Allen, Timothy M. Hospedales",
      "year": 2019,
      "annotation": "Relevant.\n\nThe candidate paper is relevant to the topic as it discusses word embeddings, a type of embedding. It provides insights into the properties and behaviors of word embeddings, specifically those generated by neural network methods such as word2vec. The paper delves into the mathematical and probabilistic aspects of word embeddings, which are key to understanding what embeddings are and how they work.",
      "abstract": "Word embeddings generated by neural network methods such as word2vec (W2V) are well known to exhibit seemingly linear behaviour, e.g. the of analogy \"woman is queen man king\" approximately describe a parallelogram. This property particularly intriguing since not trained achieve it. Several explanations have been proposed, but each introduces assumptions that do hold in practice. We derive probabilistically grounded definition paraphrasing we re-interpret word transformation, mathematical description \"$w_x$ $w_y$\". From these concepts prove existence relationships between W2V-type underlie analogical phenomenon, identifying explicit error terms."
    },
    {
      "id": "https://openalex.org/W2787481916",
      "title": "A Survey of Word Embeddings Evaluation Methods",
      "authors": "Amir Bakarov",
      "year": 2018,
      "annotation": "The candidate paper is relevant to the intellectual context of the topic. The paper discusses word embeddings, which are a type of embedding. It provides an overview of the evaluation methods for word embeddings, which is an important aspect of understanding and utilizing embeddings. Therefore, it can contribute to the understanding of the topic.",
      "abstract": "Word embeddings are real-valued word representations able to capture lexical semantics and trained on natural language corpora. Models proposing these have gained popularity in the recent years, but issue of most adequate evaluation method still remains open. This paper presents an extensive overview field evaluation, highlighting main problems a typology approaches summarizing 16 intrinsic methods 12 extrinsic methods. I describe both widely-used experimental methods, systematize information about datasets discuss some key challenges."
    }
  ]
}